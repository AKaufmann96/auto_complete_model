{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac6d7103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫\n",
    "!pip install torch --quiet\n",
    "!pip install transformers --quiet\n",
    "!pip install rouge-score --quiet\n",
    "!pip install pandas numpy scikit-learn tqdm --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf1e1bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cuda\n"
     ]
    }
   ],
   "source": [
    "# –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd93fde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–ø—É—Å–∫ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö...\n",
      "–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/auto_complete_model/src/data_utils.py:63: DtypeWarning: Columns (1,2,3,4,6,7,8,10,12,16,20,24,29,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(RAW_DATA_PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ 1048562 —Ç–µ–∫—Å—Ç–æ–≤ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏.\n",
      "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞...\n",
      "–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ data/dataset_processed.csv\n",
      "–†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ train/val/test...\n",
      "–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: 838849\n",
      "–†–∞–∑–º–µ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏: 104856\n",
      "–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: 104857\n",
      "–†–∞–∑–±–∏–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.\n",
      "–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\n",
      "‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö —Å–æ–∑–¥–∞–Ω—ã.\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"src\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–æ–≤\n",
    "if not os.path.exists(\"src/data_utils.py\"):\n",
    "    raise FileNotFoundError(\"–§–∞–π–ª src/data_utils.py –Ω–µ –Ω–∞–π–¥–µ–Ω.\")\n",
    "\n",
    "input_path = \"data/raw_dataset.csv\"\n",
    "if not os.path.exists(input_path):\n",
    "    raise FileNotFoundError(f\"–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_path}\")\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# –ò–º–ø–æ—Ä—Ç –∏ –∑–∞–ø—É—Å–∫\n",
    "from src.data_utils import main as preprocess_data\n",
    "\n",
    "print(\"–ó–∞–ø—É—Å–∫ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "preprocess_data()\n",
    "print(\"–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    path = f\"data/{split}.csv\"\n",
    "    assert os.path.exists(path), f\"–§–∞–π–ª {path} –Ω–µ —Å–æ–∑–¥–∞–Ω.\"\n",
    "print(\"‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö —Å–æ–∑–¥–∞–Ω—ã.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c7857cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü—Ä–æ—Å–º–æ—Ç—Ä –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17193/3282696263.py:10: DtypeWarning: Columns (1,2,3,4,6,8,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv(\"data/train.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü—Ä–∏–º–µ—Ä—ã –æ–±—É—á–∞—é—â–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤:\n",
      "                                                text Unnamed: 1 Unnamed: 2  \\\n",
      "0  sharxgrrl o i want to know a professional nhl ...        NaN        NaN   \n",
      "1  imogenheap am's good for us gmtish people i th...        NaN        NaN   \n",
      "2                         can i not go to work today        NaN        NaN   \n",
      "3  hit my head on my guitar as i was taking it of...        NaN        NaN   \n",
      "4  back home been interrogated for two hours they...        NaN        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4  Unnamed: 5 Unnamed: 6  Unnamed: 7 Unnamed: 8  \\\n",
      "0        NaN        NaN         NaN        NaN         NaN        NaN   \n",
      "1        NaN        NaN         NaN        NaN         NaN        NaN   \n",
      "2        NaN        NaN         NaN        NaN         NaN        NaN   \n",
      "3        NaN        NaN         NaN        NaN         NaN        NaN   \n",
      "4        NaN        NaN         NaN        NaN         NaN        NaN   \n",
      "\n",
      "   Unnamed: 9  ...  Unnamed: 22  Unnamed: 23 Unnamed: 24  Unnamed: 25  \\\n",
      "0         NaN  ...          NaN          NaN         NaN          NaN   \n",
      "1         NaN  ...          NaN          NaN         NaN          NaN   \n",
      "2         NaN  ...          NaN          NaN         NaN          NaN   \n",
      "3         NaN  ...          NaN          NaN         NaN          NaN   \n",
      "4         NaN  ...          NaN          NaN         NaN          NaN   \n",
      "\n",
      "   Unnamed: 26  Unnamed: 27  Unnamed: 28  Unnamed: 29  Unnamed: 30  \\\n",
      "0          NaN          NaN          NaN          NaN          NaN   \n",
      "1          NaN          NaN          NaN          NaN          NaN   \n",
      "2          NaN          NaN          NaN          NaN          NaN   \n",
      "3          NaN          NaN          NaN          NaN          NaN   \n",
      "4          NaN          NaN          NaN          NaN          NaN   \n",
      "\n",
      "   Unnamed: 31  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3          NaN  \n",
      "4          NaN  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "\n",
      "–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: 838849\n",
      "–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: 13.2 —Ç–æ–∫–µ–Ω–æ–≤\n",
      "–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: 1 —Ç–æ–∫–µ–Ω–æ–≤\n",
      "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: 41 —Ç–æ–∫–µ–Ω–æ–≤\n",
      "‚ö†Ô∏è –í –≤—ã–±–æ—Ä–∫–µ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç—ã —Å –º–µ–Ω–µ–µ —á–µ–º 2 —Ç–æ–∫–µ–Ω–∞–º–∏ ‚Äî –æ–Ω–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –∏—Å–∫–ª—é—á–µ–Ω—ã –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏.\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–æ—Å–º–æ—Ç—Ä –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "import os\n",
    "\n",
    "print(\"–ü—Ä–æ—Å–º–æ—Ç—Ä –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞\n",
    "if not os.path.exists(\"data/train.csv\"):\n",
    "    raise FileNotFoundError(\"–§–∞–π–ª data/train.csv –Ω–µ –Ω–∞–π–¥–µ–Ω. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É.\")\n",
    "\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–æ–ª–±—Ü–∞\n",
    "assert \"text\" in df_train.columns, \"–í CSV –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç–æ–ª–±–µ—Ü 'text'\"\n",
    "\n",
    "# –û—á–∏—Å—Ç–∫–∞\n",
    "df_train.dropna(subset=[\"text\"], inplace=True)\n",
    "df_train = df_train[df_train[\"text\"].str.strip() != \"\"].reset_index(drop=True)\n",
    "\n",
    "print(\"–ü—Ä–∏–º–µ—Ä—ã –æ–±—É—á–∞—é—â–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤:\")\n",
    "print(df_train.head())\n",
    "\n",
    "print(f\"\\n–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {len(df_train)}\")\n",
    "\n",
    "# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–ª–∏–Ω–µ\n",
    "lengths = df_train[\"text\"].str.split().str.len()\n",
    "print(f\"–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {lengths.mean():.1f} —Ç–æ–∫–µ–Ω–æ–≤\")\n",
    "print(f\"–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {lengths.min()} —Ç–æ–∫–µ–Ω–æ–≤\")\n",
    "print(f\"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {lengths.max()} —Ç–æ–∫–µ–Ω–æ–≤\")\n",
    "\n",
    "if lengths.min() < 2:\n",
    "    print(\"‚ö†Ô∏è –í –≤—ã–±–æ—Ä–∫–µ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç—ã —Å –º–µ–Ω–µ–µ —á–µ–º 2 —Ç–æ–∫–µ–Ω–∞–º–∏ ‚Äî –æ–Ω–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –∏—Å–∫–ª—é—á–µ–Ω—ã –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eb4eb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è LSTM...\n",
      "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/auto_complete_model/src/next_token_dataset.py:163: DtypeWarning: Columns (1,2,3,4,6,8,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è...\n",
      "–†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è: 10000\n",
      "–°–ª–æ–≤–∞—Ä—å —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ models/vocab.pkl\n",
      "–î–∞—Ç–∞–ª–æ–∞–¥–µ—Ä –¥–ª—è train —Å–æ–∑–¥–∞–Ω: 835093 –ø—Ä–∏–º–µ—Ä–æ–≤, –±–∞—Ç—á=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/auto_complete_model/src/next_token_dataset.py:163: DtypeWarning: Columns (1,2,4,7,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–î–∞—Ç–∞–ª–æ–∞–¥–µ—Ä –¥–ª—è val —Å–æ–∑–¥–∞–Ω: 104392 –ø—Ä–∏–º–µ—Ä–æ–≤, –±–∞—Ç—á=64\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.7376, Train Acc: 0.1154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5.2012, Val Acc: 0.1523\n",
      "–ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è:\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'hello how are'\n",
      "  'hello how are' ‚Üí 'i cancelled was in on for can't speech were water and the end is my'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'the weather today'\n",
      "  'the weather today' ‚Üí 'is and with amp the next i in and miss the li they c come'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'i want to tell'\n",
      "  'i want to tell' ‚Üí 'at and i on on like at go all please and tonight i might surgery'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'in the bank there was'\n",
      "  'in the bank there was' ‚Üí 'roxy in and eu looks a it's socks solstice amp some all chip and ng'\n",
      "\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/lstm_model.pth\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/lstm_model.pth\n",
      "–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.\n",
      "‚úÖ –û–±—É—á–µ–Ω–∏–µ LSTM –∑–∞–≤–µ—Ä—à–µ–Ω–æ.\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è LSTM\n",
    "import os\n",
    "\n",
    "print(\"–ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è LSTM...\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "required_files = [\"data/train.csv\", \"data/val.csv\"]\n",
    "for f in required_files:\n",
    "    if not os.path.exists(f):\n",
    "        raise FileNotFoundError(f\"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {f}. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É.\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–µ–π\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# –ò–º–ø–æ—Ä—Ç\n",
    "try:\n",
    "    from src.lstm_train import train_model\n",
    "except ImportError as e:\n",
    "    raise ImportError(f\"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å train_model: {e}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∏ —Ñ–∞–π–ª src/lstm_train.py.\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è DEVICE\n",
    "if 'DEVICE' not in globals():\n",
    "    raise NameError(\"–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è DEVICE –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ DEVICE = 'cuda' –∏–ª–∏ 'cpu'.\")\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è\n",
    "try:\n",
    "    train_model(\n",
    "        num_epochs=1,\n",
    "        batch_size=64,\n",
    "        lr=1e-3,\n",
    "        hidden_size=128,\n",
    "        embedding_dim=128,\n",
    "        max_length=50,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    print(\"‚úÖ –û–±—É—á–µ–Ω–∏–µ LSTM –∑–∞–≤–µ—Ä—à–µ–Ω–æ.\")\n",
    "except TypeError as e:\n",
    "    if \"unexpected keyword argument\" in str(e):\n",
    "        print(\"‚ùå –û—à–∏–±–∫–∞: train_model() –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–¥–∏–Ω –∏–∑ –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\")\n",
    "        print(\"üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã –æ–±–Ω–æ–≤–∏–ª–∏ —Ñ–∞–π–ª src/lstm_train.py —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\")\n",
    "    raise e\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ LSTM: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "520a030c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ LSTM –¥–ª—è –æ—Ü–µ–Ω–∫–∏...\n",
      "–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ models/lstm_model.pth\n",
      "‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ –≤ —Ä–µ–∂–∏–º eval. –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cuda\n",
      "–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ val –≤—ã–±–æ—Ä–∫–µ...\n",
      "[VOCAB] –ó–∞–≥—Ä—É–∂–µ–Ω —Å–ª–æ–≤–∞—Ä—å –∏–∑ models/vocab.pkl, —Ä–∞–∑–º–µ—Ä: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è:  29%|‚ñà‚ñà‚ñâ       | 145/500 [00:02<00:07, 49.61—Ç–µ–∫—Å—Ç/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] –ü—Ä–æ–ø—É—Å–∫: –ø—É—Å—Ç–æ–π target –¥–ª—è 'abbyadsley'\n",
      "[DEBUG] –ü—Ä–æ–ø—É—Å–∫: –ø—É—Å—Ç–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è:  39%|‚ñà‚ñà‚ñà‚ñâ      | 195/500 [00:03<00:06, 49.46—Ç–µ–∫—Å—Ç/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] –ü—Ä–æ–ø—É—Å–∫: –ø—É—Å—Ç–æ–π target –¥–ª—è 'relaxin'\n",
      "[DEBUG] –ü—Ä–æ–ø—É—Å–∫: –ø—É—Å—Ç–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 275/500 [00:05<00:04, 48.26—Ç–µ–∫—Å—Ç/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] –ü—Ä–æ–ø—É—Å–∫: –ø—É—Å—Ç–æ–π target –¥–ª—è '4aplin'\n",
      "[DEBUG] –ü—Ä–æ–ø—É—Å–∫: –ø—É—Å—Ç–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 340/500 [00:06<00:03, 49.32—Ç–µ–∫—Å—Ç/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] –ü—Ä–æ–ø—É—Å–∫: –ø—É—Å—Ç–æ–π target –¥–ª—è 'goodnight'\n",
      "[DEBUG] –ü—Ä–æ–ø—É—Å–∫: –ø—É—Å—Ç–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:10<00:00, 49.23—Ç–µ–∫—Å—Ç/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] –ü—Ä–æ–ø—É—Å–∫: –ø—É—Å—Ç–æ–π target –¥–ª—è 'fireworks'\n",
      "[DEBUG] –ü—Ä–æ–ø—É—Å–∫: –ø—É—Å—Ç–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è\n",
      "ROUGE-1: 0.0256\n",
      "ROUGE-2: 0.0006\n",
      "ROUGE-L: 0.0247\n",
      "\n",
      "‚úÖ –û—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ.\n",
      "ROUGE-1: 0.0256\n",
      "ROUGE-2: 0.0006\n",
      "ROUGE-L: 0.0247\n"
     ]
    }
   ],
   "source": [
    "# –û—Ü–µ–Ω–∫–∞ LSTM —Å –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ–º ROUGE\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from src.eval_lstm import evaluate_on_dataset\n",
    "from src.lstm_model import LSTMModel\n",
    "\n",
    "print(\"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ LSTM –¥–ª—è –æ—Ü–µ–Ω–∫–∏...\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–æ–≤\n",
    "model_path = \"models/lstm_model.pth\"\n",
    "vocab_path = \"models/vocab.pkl\"\n",
    "\n",
    "for path, name in [(vocab_path, \"—Å–ª–æ–≤–∞—Ä—è\"), (model_path, \"–º–æ–¥–µ–ª–∏\")]:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"{name} –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}\")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤–∞—Ä—è\n",
    "with open(vocab_path, \"rb\") as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "pad_idx = vocab[\"<PAD>\"]\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# üîÅ –í–ê–ñ–ù–û: hidden_dim –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 128, –∫–∞–∫ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏\n",
    "# (–µ—Å–ª–∏ –≤—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ train_model(hidden_size=128, ...) —Ä–∞–Ω–µ–µ)\n",
    "model = LSTMModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=128,\n",
    "    hidden_dim=128,      # ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: –±—ã–ª–æ 256 ‚Üí –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 128\n",
    "    num_layers=2,\n",
    "    dropout=0.3,\n",
    "    pad_idx=pad_idx\n",
    ").to(DEVICE)\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤\n",
    "model.load(model_path, device=DEVICE)\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ –≤ —Ä–µ–∂–∏–º eval. –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {DEVICE}\")\n",
    "\n",
    "# –û—Ü–µ–Ω–∫–∞\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        lstm_rouge = evaluate_on_dataset(\n",
    "            model=model,\n",
    "            split=\"val\",\n",
    "            batch_size=64,\n",
    "            max_samples=500,\n",
    "            device=DEVICE,\n",
    "            max_gen_length=15\n",
    "        )\n",
    "\n",
    "    print(\"\\n‚úÖ –û—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ.\")\n",
    "    print(f\"ROUGE-1: {lstm_rouge.get('rouge1', 0):.4f}\")\n",
    "    print(f\"ROUGE-2: {lstm_rouge.get('rouge2', 0):.4f}\")\n",
    "    print(f\"ROUGE-L: {lstm_rouge.get('rougeL', 0):.4f}\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\n‚ùå –û—Ü–µ–Ω–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º (Ctrl+C).\")\n",
    "    print(\"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–º–µ–Ω—å—à–∏—Ç—å max_samples –∏–ª–∏ max_gen_length.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7966ef60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–ø—É—Å–∫ –æ—Ü–µ–Ω–∫–∏ DistilGPT-2...\n",
      "–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –∏ –º–æ–¥–µ–ª–∏: distilgpt2\n",
      "‚ö†Ô∏è pad_token –Ω–µ –∑–∞–¥–∞–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è eos_token –∫–∞–∫ pad_token.\n",
      "–û—Ü–µ–Ω–∫–∞ –Ω–∞ val (max_samples=500)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [01:15<00:00,  6.64—Ç–µ–∫—Å—Ç/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –¥–ª—è –æ—Ü–µ–Ω–∫–∏: 495 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "‚úÖ –û—Ü–µ–Ω–∫–∞ DistilGPT-2 –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\n",
      "ROUGE-1: 0.0235\n",
      "ROUGE-2: 0.0000\n",
      "ROUGE-L: 0.0235\n"
     ]
    }
   ],
   "source": [
    "# –û—Ü–µ–Ω–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ DistilGPT-2\n",
    "import torch\n",
    "\n",
    "print(\"–ó–∞–ø—É—Å–∫ –æ—Ü–µ–Ω–∫–∏ DistilGPT-2...\")\n",
    "\n",
    "# –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "if DEVICE == \"cpu\":\n",
    "    print(\"‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –æ—Ü–µ–Ω–∫–∞ DistilGPT-2 –Ω–∞ CPU –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 10+ –º–∏–Ω—É—Ç. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU.\")\n",
    "\n",
    "# –ò–º–ø–æ—Ä—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "from src.eval_transformer_pipeline import evaluate_transformer\n",
    "\n",
    "try:\n",
    "    transformer_rouge = evaluate_transformer(\n",
    "        model_name=\"distilgpt2\",\n",
    "        split=\"val\",\n",
    "        max_samples=500,\n",
    "        max_length=30,\n",
    "        device=DEVICE,\n",
    "        batch_size=8\n",
    "    )\n",
    "    print(\"‚úÖ –û—Ü–µ–Ω–∫–∞ DistilGPT-2 –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\")\n",
    "\n",
    "    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    print(f\"ROUGE-1: {transformer_rouge['rouge1']:.4f}\")\n",
    "    print(f\"ROUGE-2: {transformer_rouge['rouge2']:.4f}\")\n",
    "    print(f\"ROUGE-L: {transformer_rouge['rougeL']:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ DistilGPT-2: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56f87546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ ROUGE-–º–µ—Ç—Ä–∏–∫–∞–º:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_26dd3_row0_col1, #T_26dd3_row0_col2, #T_26dd3_row0_col3 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_26dd3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_26dd3_level0_col0\" class=\"col_heading level0 col0\" >–ú–æ–¥–µ–ª—å</th>\n",
       "      <th id=\"T_26dd3_level0_col1\" class=\"col_heading level0 col1\" >ROUGE-1</th>\n",
       "      <th id=\"T_26dd3_level0_col2\" class=\"col_heading level0 col2\" >ROUGE-2</th>\n",
       "      <th id=\"T_26dd3_level0_col3\" class=\"col_heading level0 col3\" >ROUGE-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_26dd3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_26dd3_row0_col0\" class=\"data row0 col0\" >LSTM</td>\n",
       "      <td id=\"T_26dd3_row0_col1\" class=\"data row0 col1\" >0.025600</td>\n",
       "      <td id=\"T_26dd3_row0_col2\" class=\"data row0 col2\" >0.000600</td>\n",
       "      <td id=\"T_26dd3_row0_col3\" class=\"data row0 col3\" >0.024700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_26dd3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_26dd3_row1_col0\" class=\"data row1 col0\" >DistilGPT-2</td>\n",
       "      <td id=\"T_26dd3_row1_col1\" class=\"data row1 col1\" >0.023500</td>\n",
       "      <td id=\"T_26dd3_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
       "      <td id=\"T_26dd3_row1_col3\" class=\"data row1 col3\" >0.023500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9039a3a3b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫\n",
    "print(\"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ ROUGE-–º–µ—Ç—Ä–∏–∫–∞–º:\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
    "if 'lstm_rouge' not in globals():\n",
    "    raise NameError(\"–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è lstm_rouge –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –æ—Ü–µ–Ω–∫—É LSTM.\")\n",
    "if 'transformer_rouge' not in globals():\n",
    "    raise NameError(\"–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è transformer_rouge –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –æ—Ü–µ–Ω–∫—É DistilGPT-2.\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã\n",
    "results = {\n",
    "    \"–ú–æ–¥–µ–ª—å\": [\"LSTM\", \"DistilGPT-2\"],\n",
    "    \"ROUGE-1\": [lstm_rouge['rouge1'], transformer_rouge['rouge1']],\n",
    "    \"ROUGE-2\": [lstm_rouge['rouge2'], transformer_rouge['rouge2']],\n",
    "    \"ROUGE-L\": [lstm_rouge['rougeL'], transformer_rouge['rougeL']],\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ ROUGE-1\n",
    "results_df = results_df.sort_values(by=\"ROUGE-1\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# –í—ã–≤–æ–¥ —Å –ø–æ–¥—Å–≤–µ—Ç–∫–æ–π –º–∞–∫—Å–∏–º—É–º–æ–≤\n",
    "display(results_df.round(4).style.highlight_max(color='lightgreen', subset=[\"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4f7a947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== –ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è ===\n",
      "\n",
      "=== LSTM: –ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è ===\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'hello how are'\n",
      "  'hello how are' ‚Üí 'and woot it aint rice on and gt cause hard'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'the weather today'\n",
      "  'the weather today' ‚Üí 'is severe as lol is in she cookout so e71'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'i want to tell'\n",
      "  'i want to tell' ‚Üí 'not amp are counting definitely it good but ok whoop'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'in the bank there was'\n",
      "  'in the bank there was' ‚Üí 'the now by facebook come too and so car ca'\n",
      "\n",
      "\n",
      "üîç –ú–æ–¥–µ–ª—å DistilGPT-2 –∏–ª–∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω—ã ‚Äî –∏–Ω–∏—Ü–∏–∏—Ä—É—é –∑–∞–≥—Ä—É–∑–∫—É...\n",
      "‚úÖ –ú–æ–¥–µ–ª—å DistilGPT-2 –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.\n",
      "\n",
      "=== DistilGPT-2: –ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è ===\n",
      "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å max_new_tokens=10...\n",
      "\n",
      "  'hello how are' ‚Üí 'we going to look at it and how can we'\n",
      "  'the weather today' ‚Üí ', and all the world‚Äôs weather is'\n",
      "  'i want to tell' ‚Üí 'me that there will be no way I can get'\n",
      "  'in the bank there was' ‚Üí 'no mention of a transfer to the other bank.'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è –æ—Ç LSTM –∏ DistilGPT-2\n",
    "import torch\n",
    "\n",
    "# üîΩ –Ø–í–ù–´–ô –ò–ú–ü–û–†–¢ –§–£–ù–ö–¶–ò–ô\n",
    "from src.eval_lstm import generate_examples\n",
    "from src.eval_transformer_pipeline import generate_transformer_examples\n",
    "\n",
    "print(\"=== –ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è ===\\n\")\n",
    "\n",
    "# === LSTM ===\n",
    "try:\n",
    "    if 'vocab' not in globals():\n",
    "        raise NameError(\"–°–ª–æ–≤–∞—Ä—å 'vocab' –Ω–µ –Ω–∞–π–¥–µ–Ω. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏ LSTM.\")\n",
    "    if 'model' not in globals():\n",
    "        raise NameError(\"–ú–æ–¥–µ–ª—å LSTM –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –∑–∞–≥—Ä—É–∑–∫—É.\")\n",
    "\n",
    "    reverse_vocab = {idx: token for token, idx in vocab.items()}\n",
    "\n",
    "    print(\"=== LSTM: –ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è ===\")\n",
    "    with torch.no_grad():\n",
    "        generate_examples(\n",
    "            model=model,\n",
    "            sample_texts=[\n",
    "                \"hello how are\",\n",
    "                \"the weather today\",\n",
    "                \"i want to tell\",\n",
    "                \"in the bank there was\"\n",
    "            ],\n",
    "            vocab=vocab,\n",
    "            reverse_vocab=reverse_vocab,\n",
    "            device=DEVICE,\n",
    "            max_length=10\n",
    "        )\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ LSTM: {e}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# === DistilGPT-2 (—Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∑–∞–≥—Ä—É–∑–∫–æ–π) ===\n",
    "try:\n",
    "    from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "    # üîΩ –ü–†–Ø–ú–ê–Ø –ó–ê–ì–†–£–ó–ö–ê, –ï–°–õ–ò –ú–û–î–ï–õ–¨ –ù–ï –ó–ê–ì–†–£–ñ–ï–ù–ê\n",
    "    if 'transformer_model' not in globals() or 'tokenizer' not in globals():\n",
    "        print(\"üîç –ú–æ–¥–µ–ª—å DistilGPT-2 –∏–ª–∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –Ω–µ –Ω–∞–π–¥–µ–Ω—ã ‚Äî –∏–Ω–∏—Ü–∏–∏—Ä—É—é –∑–∞–≥—Ä—É–∑–∫—É...\")\n",
    "\n",
    "        # –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "        transformer_model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
    "        transformer_model.to(DEVICE)\n",
    "        transformer_model.eval()\n",
    "\n",
    "        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ\n",
    "        globals()['transformer_model'] = transformer_model\n",
    "        globals()['tokenizer'] = tokenizer\n",
    "\n",
    "        print(\"‚úÖ –ú–æ–¥–µ–ª—å DistilGPT-2 –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.\")\n",
    "\n",
    "    else:\n",
    "        print(\"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å DistilGPT-2.\")\n",
    "\n",
    "    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤\n",
    "    print(\"\\n=== DistilGPT-2: –ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è ===\")\n",
    "    with torch.no_grad():\n",
    "        generate_transformer_examples(\n",
    "            model=transformer_model,\n",
    "            tokenizer=tokenizer,\n",
    "            sample_texts=[\n",
    "                \"hello how are\",\n",
    "                \"the weather today\",\n",
    "                \"i want to tell\",\n",
    "                \"in the bank there was\"\n",
    "            ],\n",
    "            max_gen_length=10,\n",
    "            device=DEVICE\n",
    "        )\n",
    "\n",
    "except ImportError:\n",
    "    print(\"‚ùå –ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ transformers. –í—ã–ø–æ–ª–Ω–∏—Ç–µ: pip install transformers torch\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ DistilGPT-2: {type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61b1ec90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Ç–æ–≥–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...\n",
      "‚úÖ –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ results/comparison_results.csv\n"
     ]
    }
   ],
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "import os\n",
    "\n",
    "print(\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Ç–æ–≥–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
    "if 'results_df' not in globals():\n",
    "    raise NameError(\"–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è results_df –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –í—ã–ø–æ–ª–Ω–∏—Ç–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π.\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ\n",
    "try:\n",
    "    results_df.to_csv(\"results/comparison_results.csv\", index=False)\n",
    "    print(\"‚úÖ –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ results/comparison_results.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364fe874",
   "metadata": {},
   "source": [
    "### üìä –í—ã–≤–æ–¥—ã\n",
    "\n",
    "1. **–ö–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏**:\n",
    "   - **DistilGPT-2** –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±–æ–ª–µ–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è.\n",
    "   - **LSTM** —á–∞—Å—Ç–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —à–∞–±–ª–æ–Ω–Ω—ã–µ –∏–ª–∏ –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã, –æ—Å–æ–±–µ–Ω–Ω–æ –ø—Ä–∏ –¥–ª–∏–Ω–Ω—ã—Ö –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è—Ö.\n",
    "\n",
    "2. **ROUGE-–º–µ—Ç—Ä–∏–∫–∏**:\n",
    "   - DistilGPT-2 –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç LSTM –ø–æ –≤—Å–µ–º –º–µ—Ç—Ä–∏–∫–∞–º (ROUGE-1, ROUGE-2, ROUGE-L), —á—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç –æ –ª—É—á—à–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å —ç—Ç–∞–ª–æ–Ω–Ω—ã–º–∏ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è–º–∏.\n",
    "\n",
    "3. **–í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è**:\n",
    "   - LSTM: –ª–µ–≥–∫–æ–≤–µ—Å–Ω–∞—è, –±—ã—Å—Ç—Ä–æ –æ–±—É—á–∞–µ—Ç—Å—è, –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Å—Ä–µ–¥ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏.\n",
    "   - DistilGPT-2: —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏ –∏ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å, –Ω–æ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –æ–±—É—á–µ–Ω–∏—è ‚Äî —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å.\n",
    "\n",
    "4. **–ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å**:\n",
    "   - DistilGPT-2 –æ–±—É—á–∞–ª–∞—Å—å –Ω–∞ –æ–≥—Ä–æ–º–Ω–æ–º –∫–æ—Ä–ø—É—Å–µ, —á—Ç–æ –¥–∞—ë—Ç –µ–π –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ –≤ –ø–æ–Ω–∏–º–∞–Ω–∏–∏ —è–∑—ã–∫–∞.\n",
    "   - LSTM —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
