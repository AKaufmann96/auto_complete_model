{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac6d7103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./venv/lib/python3.10/site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in ./venv/lib/python3.10/site-packages (0.22.1)\n",
      "Requirement already satisfied: torchaudio in ./venv/lib/python3.10/site-packages (2.7.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./venv/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./venv/lib/python3.10/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.10/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./venv/lib/python3.10/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./venv/lib/python3.10/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./venv/lib/python3.10/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./venv/lib/python3.10/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./venv/lib/python3.10/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./venv/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./venv/lib/python3.10/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./venv/lib/python3.10/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./venv/lib/python3.10/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: triton==3.3.1 in ./venv/lib/python3.10/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./venv/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./venv/lib/python3.10/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./venv/lib/python3.10/site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./venv/lib/python3.10/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./venv/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in ./venv/lib/python3.10/site-packages (from triton==3.3.1->torch) (59.6.0)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.10/site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./venv/lib/python3.10/site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: transformers in ./venv/lib/python3.10/site-packages (4.52.4)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./venv/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./venv/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./venv/lib/python3.10/site-packages (from transformers) (0.32.4)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: rouge-score in ./venv/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in ./venv/lib/python3.10/site-packages (from rouge-score) (2.3.0)\n",
      "Requirement already satisfied: nltk in ./venv/lib/python3.10/site-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.10/site-packages (from rouge-score) (2.2.6)\n",
      "Requirement already satisfied: six>=1.14.0 in ./venv/lib/python3.10/site-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.10/site-packages (from nltk->rouge-score) (8.2.1)\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.10/site-packages (from nltk->rouge-score) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.10/site-packages (from nltk->rouge-score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.10/site-packages (from nltk->rouge-score) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.10/site-packages (1.7.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.10/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in ./venv/lib/python3.10/site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./venv/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./venv/lib/python3.10/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.10/site-packages (2.2.6)\n"
     ]
    }
   ],
   "source": [
    "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install transformers\n",
    "!pip install rouge-score\n",
    "!pip install scikit-learn\n",
    "!pip install tqdm\n",
    "!pip install pandas\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf1e1bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd93fde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/auto_complete_model/src/data_utils.py:55: DtypeWarning: Columns (1,2,3,4,6,7,8,10,12,16,20,24,29,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(RAW_DATA_PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ 1048562 —Ç–µ–∫—Å—Ç–æ–≤.\n",
      "–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤...\n",
      "–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ data/dataset_processed.csv\n",
      "–†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ train/val/test...\n",
      "–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: 838849\n",
      "–†–∞–∑–º–µ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏: 104856\n",
      "–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: 104857\n",
      "–†–∞–∑–±–∏–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.\n"
     ]
    }
   ],
   "source": [
    "# –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö\n",
    "# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ data_utils.py\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "\n",
    "from src.data_utils import main as preprocess_data\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n",
    "preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c7857cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü—Ä–∏–º–µ—Ä—ã –æ–±—É—á–∞—é—â–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤:\n",
      "                                                text  \\\n",
      "0  sharxgrrl o i want to know a professional nhl ...   \n",
      "1  imogenheap am's good for us gmtish people i th...   \n",
      "2                         can i not go to work today   \n",
      "3  hit my head on my guitar as i was taking it of...   \n",
      "4  back home been interrogated for two hours they...   \n",
      "\n",
      "                                              tokens  \n",
      "0  ['sharxgrrl', 'o', 'i', 'want', 'to', 'know', ...  \n",
      "1  ['imogenheap', \"am's\", 'good', 'for', 'us', 'g...  \n",
      "2   ['can', 'i', 'not', 'go', 'to', 'work', 'today']  \n",
      "3  ['hit', 'my', 'head', 'on', 'my', 'guitar', 'a...  \n",
      "4  ['back', 'home', 'been', 'interrogated', 'for'...  \n",
      "\n",
      "–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: 838849\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–æ—Å–º–æ—Ç—Ä –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "print(\"–ü—Ä–∏–º–µ—Ä—ã –æ–±—É—á–∞—é—â–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤:\")\n",
    "print(df_train.head())\n",
    "print(f\"\\n–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {len(df_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eb4eb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cuda\n",
      "–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è...\n",
      "–†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è: 10000\n",
      "–°–ª–æ–≤–∞—Ä—å —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ models/vocab.pkl\n",
      "–î–∞—Ç–∞–ª–æ–∞–¥–µ—Ä –¥–ª—è train —Å–æ–∑–¥–∞–Ω: 838849 –ø—Ä–∏–º–µ—Ä–æ–≤, –±–∞—Ç—á=256\n",
      "–î–∞—Ç–∞–ª–æ–∞–¥–µ—Ä –¥–ª—è val —Å–æ–∑–¥–∞–Ω: 104856 –ø—Ä–∏–º–µ—Ä–æ–≤, –±–∞—Ç—á=256\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6.0811, Train Acc: 0.1432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5.4144, Val Acc: 0.1824\n",
      "–ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è:\n",
      "  'hello how are' ‚Üí 'cute text me happy one year too far away lol'\n",
      "  'the weather today' ‚Üí 'morning lol sometimes lol lt3 x haha lol thing fb'\n",
      "  'i want to tell' ‚Üí 'it all up x though x x x lol ftw'\n",
      "  'in the bank there was' ‚Üí 'time up again tonight sigh xx not possible out soon'\n",
      "\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/lstm_model.pth\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/lstm_model.pth\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 5.2589, Train Acc: 0.1908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5.0294, Val Acc: 0.2111\n",
      "–ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è:\n",
      "  'hello how are' ‚Üí 'you doin you feel better soon how sorry lt3 you'\n",
      "  'the weather today' ‚Üí 'seems over it lol now x x x x x'\n",
      "  'i want to tell' ‚Üí 'it lt3 lt3 x x x x x x x'\n",
      "  'in the bank there was' ‚Üí 'not me anymore xx yet x x x x x'\n",
      "\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/lstm_model.pth\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/lstm_model.pth\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.9529, Train Acc: 0.2098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 4.8714, Val Acc: 0.2240\n",
      "–ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è:\n",
      "  'hello how are' ‚Üí 'you doing today again ha xx xxxx no more tomorrow'\n",
      "  'the weather today' ‚Üí 'x x x xxx x xxx x x x x'\n",
      "  'i want to tell' ‚Üí 'me again ' xx p x x x x x'\n",
      "  'in the bank there was' ‚Üí 'us bars later lol plz xd jk xx haha x'\n",
      "\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/lstm_model.pth\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/lstm_model.pth\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.7684, Train Acc: 0.2216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 4.7930, Val Acc: 0.2348\n",
      "–ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è:\n",
      "  'hello how are' ‚Üí 'you doing lol tomorrow x x x x x x'\n",
      "  'the weather today' ‚Üí 'sucks x though x x x x x x xxx'\n",
      "  'i want to tell' ‚Üí 'they met me tweet though lol me please x x'\n",
      "  'in the bank there was' ‚Üí 'hayfever though ugh xd x x x lt3 lt3 xx'\n",
      "\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/lstm_model.pth\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/lstm_model.pth\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.6392, Train Acc: 0.2292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 4.7445, Val Acc: 0.2397\n",
      "–ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è:\n",
      "  'hello how are' ‚Üí 'you doing today alone xx eh x x xx xoxo'\n",
      "  'the weather today' ‚Üí 'haha lt3 lt3 haa lt3 xx lmaoo xoxo t man'\n",
      "  'i want to tell' ‚Üí 'him right now xx xx xx though xxxx xx x'\n",
      "  'in the bank there was' ‚Üí 'yours tho haha xx xo x x x x x'\n",
      "\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/lstm_model.pth\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/lstm_model.pth\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.5396, Train Acc: 0.2353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 4.7168, Val Acc: 0.2435\n",
      "–ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è:\n",
      "  'hello how are' ‚Üí 'you today too back though xo goodnight all lt3 u'\n",
      "  'the weather today' ‚Üí 'though ugh sigh booo omg me crazy times first peace'\n",
      "  'i want to tell' ‚Üí 'him please xo me outt please hahaha haha xx lt3'\n",
      "  'in the bank there was' ‚Üí 'yours lol lol x x x xx xx xx xx'\n",
      "\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/lstm_model.pth\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/lstm_model.pth\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.4571, Train Acc: 0.2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 4.7040, Val Acc: 0.2473\n",
      "–ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è:\n",
      "  'hello how are' ‚Üí 'you today x x x x x x x x'\n",
      "  'the weather today' ‚Üí 'man sigh bummer poo boooo tears meeee anywho fb yesterday'\n",
      "  'i want to tell' ‚Üí 'him x x x x x x x x x'\n",
      "  'in the bank there was' ‚Üí 'you zack it alert lol xx l x x x'\n",
      "\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/lstm_model.pth\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/lstm_model.pth\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.3889, Train Acc: 0.2441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 4.6990, Val Acc: 0.2487\n",
      "–ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è:\n",
      "  'hello how are' ‚Üí 'you tomorrow girlie xx xx lt3 ' x x x'\n",
      "  'the weather today' ‚Üí 'unfortunately nothing serious yeah hoo haha right now lolol x'\n",
      "  'i want to tell' ‚Üí 'her jimmy johns though lol lol lol xx lol lt3'\n",
      "  'in the bank there was' ‚Üí 'mine already ahh lol night 17th today me excited xxx'\n",
      "\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/lstm_model.pth\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/lstm_model.pth\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.3289, Train Acc: 0.2474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 4.7023, Val Acc: 0.2510\n",
      "–ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è:\n",
      "  'hello how are' ‚Üí 'you today xx x muah x x x x x'\n",
      "  'the weather today' ‚Üí 'haha yay tired though l lt3 lol xxxx xxx lt3'\n",
      "  'i want to tell' ‚Üí 'you back home lmaoo down soon tho x x x'\n",
      "  'in the bank there was' ‚Üí 'yesterday sucks sigh xx x x x x x xd'\n",
      "\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.2785, Train Acc: 0.2502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 4.7088, Val Acc: 0.2523\n",
      "–ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è:\n",
      "  'hello how are' ‚Üí 'you doing now x xx xx p mwah lol x'\n",
      "  'the weather today' ‚Üí 'ugh fail sucks x x x xx xxx xd lol'\n",
      "  'i want to tell' ‚Üí 'things names please germs please booty help me vote x'\n",
      "  'in the bank there was' ‚Üí 'california enjoyable ago sigh lol lol xx xx p lt3'\n",
      "\n",
      "–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è LSTM\n",
    "from src.lstm_train import train_model\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û—Ü–µ–Ω–∫–∞ LSTM —Å –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ–º ROUGE (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)\n",
    "from src.eval_lstm import evaluate_on_dataset\n",
    "from src.lstm_model import LSTMModel\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º–µ –æ—Ü–µ–Ω–∫–∏\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤–∞—Ä—è\n",
    "with open(\"models/vocab.pkl\", \"rb\") as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "pad_idx = vocab[\"<PAD>\"]\n",
    "reverse_vocab = {idx: token for token, idx in vocab.items()}\n",
    "\n",
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\n",
    "model = LSTMModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=128,\n",
    "    hidden_dim=256,\n",
    "    num_layers=2,\n",
    "    dropout=0.3,\n",
    "    pad_idx=pad_idx\n",
    ").to(DEVICE)\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤\n",
    "model.load(\"models/lstm_model.pth\", device=DEVICE)\n",
    "model.eval()  # –†–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏\n",
    "\n",
    "print(f\"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ –≤ —Ä–µ–∂–∏–º eval. –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {DEVICE}\")\n",
    "\n",
    "try:\n",
    "    lstm_rouge = evaluate_on_dataset(\n",
    "        model=model,\n",
    "        split=\"val\",\n",
    "        batch_size=64,\n",
    "        max_samples=500,      # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≤—ã–±–æ—Ä–∫—É\n",
    "        device=DEVICE,\n",
    "        # –ü–µ—Ä–µ–¥–∞—ë–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –µ—Å–ª–∏ –æ–Ω–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è\n",
    "        max_gen_length=15,    # –ö–æ—Ä–æ—Ç–∫–∏–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è ‚Äî –±—ã—Å—Ç—Ä–µ–µ\n",
    "        disable_tqdm=False    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å\n",
    "    )\n",
    "    print(\"\\n‚úÖ –û—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ.\")\n",
    "    print(f\"ROUGE-1: {lstm_rouge['rouge-1']:.4f}\")\n",
    "    print(f\"ROUGE-2: {lstm_rouge['rouge-2']:.4f}\")\n",
    "    print(f\"ROUGE-L: {lstm_rouge['rouge-l']:.4f}\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\n‚ùå –û—Ü–µ–Ω–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º (Ctrl+C).\")\n",
    "    print(\"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–º–µ–Ω—å—à–∏—Ç—å max_samples –∏–ª–∏ max_gen_length.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5ab75a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ models/lstm_model.pth\n",
      "–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ val –≤—ã–±–æ—Ä–∫–µ...\n",
      "–î–∞—Ç–∞–ª–æ–∞–¥–µ—Ä –¥–ª—è val —Å–æ–∑–¥–∞–Ω: 104856 –ø—Ä–∏–º–µ—Ä–æ–≤, –±–∞—Ç—á=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating completions:   0%|          | 7/1639 [00:32<2:06:35,  4.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: 0.0059\n",
      "ROUGE-2: 0.0000\n",
      "ROUGE-L: 0.0058\n"
     ]
    }
   ],
   "source": [
    "# –û—Ü–µ–Ω–∫–∞ LSTM —Å –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ–º ROUGE\n",
    "from src.eval_lstm import evaluate_on_dataset\n",
    "from src.lstm_model import LSTMModel\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "with open(\"models/vocab.pkl\", \"rb\") as f:\n",
    "    vocab = pickle.load(f)\n",
    "    \n",
    "vocab_size = len(vocab)\n",
    "pad_idx = vocab[\"<PAD>\"]\n",
    "\n",
    "model = LSTMModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=128,\n",
    "    hidden_dim=256,\n",
    "    num_layers=2,\n",
    "    dropout=0.3,\n",
    "    pad_idx=pad_idx\n",
    ").to(DEVICE)\n",
    "\n",
    "model.load(\"models/lstm_model.pth\", device=DEVICE)\n",
    "\n",
    "# –û—Ü–µ–Ω–∫–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "lstm_rouge = evaluate_on_dataset(\n",
    "    model=model,\n",
    "    split=\"val\",\n",
    "    batch_size=64,\n",
    "    max_samples=500,\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7966ef60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ distilgpt2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669f77208bba48eba143058a476b60c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f966650094944d8fa060cb84983fdfdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9edc660509492da528482c1907fbec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b068ee3d313e4c06b9aa86a48c1c1642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644ff41289cf4ddca798f6ec5402702d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0f1c3a98e84d6db7726b28a8cd51aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32304fa1c8b4bf297fe92a91336e603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ú–æ–¥–µ–ª—å distilgpt2 –∑–∞–≥—Ä—É–∂–µ–Ω–∞.\n",
      "–ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è (DistilGPT-2):\n",
      "  'hello how are' ‚Üí 'you can help me grow in a world where no'\n",
      "  'the weather today' ‚Üí ')'\n",
      "  'i want to tell' ‚Üí 'be able to do that in this community.ÔøΩ'\n",
      "  'in the bank there was' ‚Üí 'of the country in an attempt to save the country'\n",
      "\n",
      "–û—Ü–µ–Ω–∫–∞ DistilGPT-2 –Ω–∞ val –≤—ã–±–æ—Ä–∫–µ...\n",
      "–î–∞—Ç–∞–ª–æ–∞–¥–µ—Ä –¥–ª—è val —Å–æ–∑–¥–∞–Ω: 104856 –ø—Ä–∏–º–µ—Ä–æ–≤, –±–∞—Ç—á=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–π:   0%|          | 508/104856 [01:59<6:48:24,  4.26it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: 0.0312\n",
      "ROUGE-2: 0.0046\n",
      "ROUGE-L: 0.0294\n",
      "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ results/transformer_val_results.csv\n"
     ]
    }
   ],
   "source": [
    "# –û—Ü–µ–Ω–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ DistilGPT-2\n",
    "from src.eval_transformer_pipeline import main as evaluate_transformer\n",
    "\n",
    "transformer_rouge = evaluate_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f87546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫\n",
    "results = {\n",
    "    \"–ú–æ–¥–µ–ª—å\": [\"LSTM\", \"DistilGPT-2\"],\n",
    "    \"ROUGE-1\": [lstm_rouge['rouge1'], transformer_rouge['rouge1']],\n",
    "    \"ROUGE-2\": [lstm_rouge['rouge2'], transformer_rouge['rouge2']],\n",
    "    \"ROUGE-L\": [lstm_rouge['rougeL'], transformer_rouge['rougeL']],\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ ROUGE-–º–µ—Ç—Ä–∏–∫–∞–º:\")\n",
    "results_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f7a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–∏–º–µ—Ä—ã –æ—Ç LSTM\n",
    "from src.lstm_model import LSTMModel\n",
    "from src.eval_lstm import generate_examples\n",
    "\n",
    "reverse_vocab = {idx: token for token, idx in vocab.items()}\n",
    "\n",
    "print(\"=== LSTM: –ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è ===\")\n",
    "generate_examples(\n",
    "    model=model,\n",
    "    sample_texts=[\"hello how are\", \"the weather today\", \"i want to tell\", \"in the bank there was\"],\n",
    "    vocab=vocab,\n",
    "    reverse_vocab=reverse_vocab,\n",
    "    device=DEVICE,\n",
    "    max_length=10\n",
    ")\n",
    "\n",
    "# –ü—Ä–∏–º–µ—Ä—ã –æ—Ç DistilGPT-2\n",
    "from src.eval_transformer_pipeline import generate_transformer_examples\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "transformer_model, tokenizer = GPT2LMHeadModel.from_pretrained(\"distilgpt2\"), GPT2Tokenizer.from_pretrained(\"distilgpt2\")\n",
    "transformer_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "transformer_model = transformer_model.to(DEVICE).eval()\n",
    "\n",
    "print(\"=== DistilGPT-2: –ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è ===\")\n",
    "generate_transformer_examples(\n",
    "    model=transformer_model,\n",
    "    tokenizer=tokenizer,\n",
    "    sample_texts=[\"hello how are\", \"the weather today\", \"i want to tell\", \"in the bank there was\"],\n",
    "    max_gen_length=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f64eb96",
   "metadata": {},
   "source": [
    "### üìä –í—ã–≤–æ–¥—ã\n",
    "\n",
    "1. **–ö–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏**:\n",
    "   - **DistilGPT-2** –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±–æ–ª–µ–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è.\n",
    "   - **LSTM** —á–∞—Å—Ç–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —à–∞–±–ª–æ–Ω–Ω—ã–µ –∏–ª–∏ –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã, –æ—Å–æ–±–µ–Ω–Ω–æ –ø—Ä–∏ –¥–ª–∏–Ω–Ω—ã—Ö –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è—Ö.\n",
    "\n",
    "2. **ROUGE-–º–µ—Ç—Ä–∏–∫–∏**:\n",
    "   - DistilGPT-2 –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç LSTM –ø–æ –≤—Å–µ–º –º–µ—Ç—Ä–∏–∫–∞–º (ROUGE-1, ROUGE-2, ROUGE-L), —á—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç –æ –ª—É—á—à–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å —ç—Ç–∞–ª–æ–Ω–Ω—ã–º–∏ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è–º–∏.\n",
    "\n",
    "3. **–í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è**:\n",
    "   - LSTM: –ª–µ–≥–∫–æ–≤–µ—Å–Ω–∞—è, –±—ã—Å—Ç—Ä–æ –æ–±—É—á–∞–µ—Ç—Å—è, –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Å—Ä–µ–¥ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏.\n",
    "   - DistilGPT-2: —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏ –∏ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å, –Ω–æ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –æ–±—É—á–µ–Ω–∏—è ‚Äî —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å.\n",
    "\n",
    "4. **–ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å**:\n",
    "   - DistilGPT-2 –æ–±—É—á–∞–ª–∞—Å—å –Ω–∞ –æ–≥—Ä–æ–º–Ω–æ–º –∫–æ—Ä–ø—É—Å–µ, —á—Ç–æ –¥–∞—ë—Ç –µ–π –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ –≤ –ø–æ–Ω–∏–º–∞–Ω–∏–∏ —è–∑—ã–∫–∞.\n",
    "   - LSTM —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b1ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "results_df.to_csv(\"results/comparison_results.csv\", index=False)\n",
    "print(\"–ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ results/comparison_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
