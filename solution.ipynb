{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6d7103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./venv/lib/python3.10/site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in ./venv/lib/python3.10/site-packages (0.22.1)\n",
      "Requirement already satisfied: torchaudio in ./venv/lib/python3.10/site-packages (2.7.1)\n",
      "Requirement already satisfied: triton==3.3.1 in ./venv/lib/python3.10/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./venv/lib/python3.10/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./venv/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./venv/lib/python3.10/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./venv/lib/python3.10/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./venv/lib/python3.10/site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./venv/lib/python3.10/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./venv/lib/python3.10/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./venv/lib/python3.10/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./venv/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.10/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./venv/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./venv/lib/python3.10/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./venv/lib/python3.10/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./venv/lib/python3.10/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./venv/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./venv/lib/python3.10/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./venv/lib/python3.10/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in ./venv/lib/python3.10/site-packages (from triton==3.3.1->torch) (59.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./venv/lib/python3.10/site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.10/site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: transformers in ./venv/lib/python3.10/site-packages (4.52.4)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./venv/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./venv/lib/python3.10/site-packages (from transformers) (0.32.4)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./venv/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: rouge-score in ./venv/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in ./venv/lib/python3.10/site-packages (from rouge-score) (2.3.0)\n",
      "Requirement already satisfied: nltk in ./venv/lib/python3.10/site-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.10/site-packages (from rouge-score) (2.2.6)\n",
      "Requirement already satisfied: six>=1.14.0 in ./venv/lib/python3.10/site-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.10/site-packages (from nltk->rouge-score) (2024.11.6)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.10/site-packages (from nltk->rouge-score) (8.2.1)\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.10/site-packages (from nltk->rouge-score) (1.5.1)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.10/site-packages (from nltk->rouge-score) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.10/site-packages (1.7.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.10/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./venv/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: numpy>=1.22.0 in ./venv/lib/python3.10/site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./venv/lib/python3.10/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.10/site-packages (2.2.6)\n"
     ]
    }
   ],
   "source": [
    "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫\n",
    "!pip install torch --quiet\n",
    "!pip install transformers --quiet\n",
    "!pip install rouge-score --quiet\n",
    "!pip install pandas numpy scikit-learn tqdm --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1e1bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cuda\n"
     ]
    }
   ],
   "source": [
    "# –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd93fde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/auto_complete_model/src/data_utils.py:55: DtypeWarning: Columns (1,2,3,4,6,7,8,10,12,16,20,24,29,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(RAW_DATA_PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ 1048562 —Ç–µ–∫—Å—Ç–æ–≤.\n",
      "–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤...\n",
      "–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ data/dataset_processed.csv\n",
      "–†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ train/val/test...\n",
      "–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: 838849\n",
      "–†–∞–∑–º–µ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏: 104856\n",
      "–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: 104857\n",
      "–†–∞–∑–±–∏–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"src\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–æ–≤\n",
    "if not os.path.exists(\"src/data_utils.py\"):\n",
    "    raise FileNotFoundError(\"–§–∞–π–ª src/data_utils.py –Ω–µ –Ω–∞–π–¥–µ–Ω.\")\n",
    "\n",
    "input_path = \"data/raw.txt\"\n",
    "if not os.path.exists(input_path):\n",
    "    raise FileNotFoundError(f\"–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_path}\")\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# –ò–º–ø–æ—Ä—Ç –∏ –∑–∞–ø—É—Å–∫\n",
    "from src.data_utils import main as preprocess_data\n",
    "\n",
    "print(\"–ó–∞–ø—É—Å–∫ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "preprocess_data()\n",
    "print(\"–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    path = f\"data/{split}.csv\"\n",
    "    assert os.path.exists(path), f\"–§–∞–π–ª {path} –Ω–µ —Å–æ–∑–¥–∞–Ω.\"\n",
    "print(\"‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö —Å–æ–∑–¥–∞–Ω—ã.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7857cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ü—Ä–∏–º–µ—Ä—ã –æ–±—É—á–∞—é—â–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤:\n",
      "                                                text  \\\n",
      "0  sharxgrrl o i want to know a professional nhl ...   \n",
      "1  imogenheap am's good for us gmtish people i th...   \n",
      "2                         can i not go to work today   \n",
      "3  hit my head on my guitar as i was taking it of...   \n",
      "4  back home been interrogated for two hours they...   \n",
      "\n",
      "                                              tokens  \n",
      "0  ['sharxgrrl', 'o', 'i', 'want', 'to', 'know', ...  \n",
      "1  ['imogenheap', \"am's\", 'good', 'for', 'us', 'g...  \n",
      "2   ['can', 'i', 'not', 'go', 'to', 'work', 'today']  \n",
      "3  ['hit', 'my', 'head', 'on', 'my', 'guitar', 'a...  \n",
      "4  ['back', 'home', 'been', 'interrogated', 'for'...  \n",
      "\n",
      "–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: 838849\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–æ—Å–º–æ—Ç—Ä –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "import os\n",
    "\n",
    "print(\"–ü—Ä–æ—Å–º–æ—Ç—Ä –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞\n",
    "if not os.path.exists(\"data/train.csv\"):\n",
    "    raise FileNotFoundError(\"–§–∞–π–ª data/train.csv –Ω–µ –Ω–∞–π–¥–µ–Ω. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É.\")\n",
    "\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–æ–ª–±—Ü–∞\n",
    "assert \"text\" in df_train.columns, \"–í CSV –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å—Ç–æ–ª–±–µ—Ü 'text'\"\n",
    "\n",
    "# –û—á–∏—Å—Ç–∫–∞\n",
    "df_train.dropna(subset=[\"text\"], inplace=True)\n",
    "df_train = df_train[df_train[\"text\"].str.strip() != \"\"].reset_index(drop=True)\n",
    "\n",
    "print(\"–ü—Ä–∏–º–µ—Ä—ã –æ–±—É—á–∞—é—â–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤:\")\n",
    "print(df_train.head())\n",
    "\n",
    "print(f\"\\n–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {len(df_train)}\")\n",
    "\n",
    "# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–ª–∏–Ω–µ\n",
    "lengths = df_train[\"text\"].str.split().str.len()\n",
    "print(f\"–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {lengths.mean():.1f} —Ç–æ–∫–µ–Ω–æ–≤\")\n",
    "print(f\"–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {lengths.min()} —Ç–æ–∫–µ–Ω–æ–≤\")\n",
    "print(f\"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {lengths.max()} —Ç–æ–∫–µ–Ω–æ–≤\")\n",
    "\n",
    "if lengths.min() < 2:\n",
    "    print(\"‚ö†Ô∏è –í –≤—ã–±–æ—Ä–∫–µ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç—ã —Å –º–µ–Ω–µ–µ —á–µ–º 2 —Ç–æ–∫–µ–Ω–∞–º–∏ ‚Äî –æ–Ω–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –∏—Å–∫–ª—é—á–µ–Ω—ã –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb4eb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è LSTM\n",
    "import os\n",
    "\n",
    "print(\"–ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è LSTM...\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "required_files = [\"data/train.csv\", \"data/val.csv\"]\n",
    "for f in required_files:\n",
    "    if not os.path.exists(f):\n",
    "        raise FileNotFoundError(f\"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {f}. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É.\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–µ–π\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# –ò–º–ø–æ—Ä—Ç\n",
    "from src.lstm_train import train_model\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (–µ—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è –∏—Ö –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç)\n",
    "try:\n",
    "    train_model(\n",
    "        num_epochs=15,\n",
    "        batch_size=64,\n",
    "        lr=1e-3,\n",
    "        hidden_size=128,\n",
    "        embedding_dim=128,\n",
    "        max_length=50,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    print(\"‚úÖ –û–±—É—á–µ–Ω–∏–µ LSTM –∑–∞–≤–µ—Ä—à–µ–Ω–æ.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ LSTM: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û—Ü–µ–Ω–∫–∞ LSTM —Å –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ–º ROUGE\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from src.eval_lstm import evaluate_on_dataset\n",
    "from src.lstm_model import LSTMModel\n",
    "\n",
    "print(\"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ LSTM –¥–ª—è –æ—Ü–µ–Ω–∫–∏...\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–æ–≤\n",
    "model_path = \"models/lstm_model.pth\"\n",
    "vocab_path = \"models/vocab.pkl\"\n",
    "\n",
    "for path, name in [(vocab_path, \"—Å–ª–æ–≤–∞—Ä—è\"), (model_path, \"–º–æ–¥–µ–ª–∏\")]:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"{name} –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}\")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤–∞—Ä—è\n",
    "with open(vocab_path, \"rb\") as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "pad_idx = vocab[\"<PAD>\"]\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\n",
    "model = LSTMModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=128,\n",
    "    hidden_dim=256,\n",
    "    num_layers=2,\n",
    "    dropout=0.3,\n",
    "    pad_idx=pad_idx\n",
    ").to(DEVICE)\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤\n",
    "model.load(model_path, device=DEVICE)\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ –≤ —Ä–µ–∂–∏–º eval. –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {DEVICE}\")\n",
    "\n",
    "# –û—Ü–µ–Ω–∫–∞\n",
    "try:\n",
    "    with torch.no_grad():  # –õ—É—á—à–µ, —á–µ–º set_grad_enabled\n",
    "        lstm_rouge = evaluate_on_dataset(\n",
    "            model=model,\n",
    "            split=\"val\",\n",
    "            batch_size=64,\n",
    "            max_samples=500,\n",
    "            device=DEVICE,\n",
    "            max_gen_length=15,\n",
    "            disable_tqdm=False\n",
    "        )\n",
    "\n",
    "    print(\"\\n‚úÖ –û—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ.\")\n",
    "    # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ –∫–ª—é—á–∏: 'rouge1', 'rouge2', 'rougeL'\n",
    "    print(f\"ROUGE-1: {lstm_rouge.get('rouge1', 0):.4f}\")\n",
    "    print(f\"ROUGE-2: {lstm_rouge.get('rouge2', 0):.4f}\")\n",
    "    print(f\"ROUGE-L: {lstm_rouge.get('rougeL', 0):.4f}\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\n‚ùå –û—Ü–µ–Ω–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º (Ctrl+C).\")\n",
    "    print(\"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–º–µ–Ω—å—à–∏—Ç—å max_samples –∏–ª–∏ max_gen_length.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7966ef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –û—Ü–µ–Ω–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ DistilGPT-2\n",
    "import torch\n",
    "\n",
    "print(\"–ó–∞–ø—É—Å–∫ –æ—Ü–µ–Ω–∫–∏ DistilGPT-2...\")\n",
    "\n",
    "# –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "if DEVICE == \"cpu\":\n",
    "    print(\"‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –æ—Ü–µ–Ω–∫–∞ DistilGPT-2 –Ω–∞ CPU –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 10+ –º–∏–Ω—É—Ç. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU.\")\n",
    "\n",
    "from src.eval_transformer_pipeline import main as evaluate_transformer\n",
    "\n",
    "try:\n",
    "    transformer_rouge = evaluate_transformer(\n",
    "        model_name=\"distilgpt2\",\n",
    "        split=\"val\",\n",
    "        max_samples=500,\n",
    "        max_length=30,\n",
    "        device=DEVICE,\n",
    "        batch_size=8\n",
    "    )\n",
    "    print(\"‚úÖ –û—Ü–µ–Ω–∫–∞ DistilGPT-2 –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\")\n",
    "\n",
    "    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    print(f\"ROUGE-1: {transformer_rouge['rouge1']:.4f}\")\n",
    "    print(f\"ROUGE-2: {transformer_rouge['rouge2']:.4f}\")\n",
    "    print(f\"ROUGE-L: {transformer_rouge['rougeL']:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ DistilGPT-2: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f87546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫\n",
    "print(\"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ ROUGE-–º–µ—Ç—Ä–∏–∫–∞–º:\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
    "if 'lstm_rouge' not in globals():\n",
    "    raise NameError(\"–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è lstm_rouge –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –æ—Ü–µ–Ω–∫—É LSTM.\")\n",
    "if 'transformer_rouge' not in globals():\n",
    "    raise NameError(\"–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è transformer_rouge –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –æ—Ü–µ–Ω–∫—É DistilGPT-2.\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã\n",
    "results = {\n",
    "    \"–ú–æ–¥–µ–ª—å\": [\"LSTM\", \"DistilGPT-2\"],\n",
    "    \"ROUGE-1\": [lstm_rouge['rouge1'], transformer_rouge['rouge1']],\n",
    "    \"ROUGE-2\": [lstm_rouge['rouge2'], transformer_rouge['rouge2']],\n",
    "    \"ROUGE-L\": [lstm_rouge['rougeL'], transformer_rouge['rougeL']],\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ ROUGE-1\n",
    "results_df = results_df.sort_values(by=\"ROUGE-1\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# –í—ã–≤–æ–¥ —Å –ø–æ–¥—Å–≤–µ—Ç–∫–æ–π –º–∞–∫—Å–∏–º—É–º–æ–≤\n",
    "display(results_df.round(4).style.highlight_max(color='lightgreen', subset=[\"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f7a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è –æ—Ç LSTM –∏ DistilGPT-2\n",
    "import torch\n",
    "\n",
    "print(\"=== –ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è ===\\n\")\n",
    "\n",
    "# === LSTM ===\n",
    "try:\n",
    "    if 'vocab' not in globals():\n",
    "        raise NameError(\"–°–ª–æ–≤–∞—Ä—å 'vocab' –Ω–µ –Ω–∞–π–¥–µ–Ω. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏ LSTM.\")\n",
    "    if 'model' not in globals():\n",
    "        raise NameError(\"–ú–æ–¥–µ–ª—å LSTM –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –∑–∞–≥—Ä—É–∑–∫—É.\")\n",
    "\n",
    "    reverse_vocab = {idx: token for token, idx in vocab.items()}\n",
    "\n",
    "    print(\"=== LSTM: –ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è ===\")\n",
    "    with torch.no_grad():\n",
    "        generate_examples(\n",
    "            model=model,\n",
    "            sample_texts=[\n",
    "                \"hello how are\",\n",
    "                \"the weather today\",\n",
    "                \"i want to tell\",\n",
    "                \"in the bank there was\"\n",
    "            ],\n",
    "            vocab=vocab,\n",
    "            reverse_vocab=reverse_vocab,\n",
    "            device=DEVICE,\n",
    "            max_length=10\n",
    "        )\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ LSTM: {e}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# === DistilGPT-2 ===\n",
    "try:\n",
    "    print(\"=== DistilGPT-2: –ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è ===\")\n",
    "    with torch.no_grad():\n",
    "        generate_transformer_examples(\n",
    "            model=transformer_model,\n",
    "            tokenizer=tokenizer,\n",
    "            sample_texts=[\n",
    "                \"hello how are\",\n",
    "                \"the weather today\",\n",
    "                \"i want to tell\",\n",
    "                \"in the bank there was\"\n",
    "            ],\n",
    "            max_gen_length=10\n",
    "        )\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ DistilGPT-2: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f64eb96",
   "metadata": {},
   "source": [
    "### üìä –í—ã–≤–æ–¥—ã\n",
    "\n",
    "1. **–ö–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏**:\n",
    "   - **DistilGPT-2** –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±–æ–ª–µ–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è.\n",
    "   - **LSTM** —á–∞—Å—Ç–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —à–∞–±–ª–æ–Ω–Ω—ã–µ –∏–ª–∏ –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã, –æ—Å–æ–±–µ–Ω–Ω–æ –ø—Ä–∏ –¥–ª–∏–Ω–Ω—ã—Ö –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è—Ö.\n",
    "\n",
    "2. **ROUGE-–º–µ—Ç—Ä–∏–∫–∏**:\n",
    "   - DistilGPT-2 –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç LSTM –ø–æ –≤—Å–µ–º –º–µ—Ç—Ä–∏–∫–∞–º (ROUGE-1, ROUGE-2, ROUGE-L), —á—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç –æ –ª—É—á—à–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å —ç—Ç–∞–ª–æ–Ω–Ω—ã–º–∏ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è–º–∏.\n",
    "\n",
    "3. **–í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è**:\n",
    "   - LSTM: –ª–µ–≥–∫–æ–≤–µ—Å–Ω–∞—è, –±—ã—Å—Ç—Ä–æ –æ–±—É—á–∞–µ—Ç—Å—è, –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Å—Ä–µ–¥ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏.\n",
    "   - DistilGPT-2: —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏ –∏ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å, –Ω–æ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –æ–±—É—á–µ–Ω–∏—è ‚Äî —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å.\n",
    "\n",
    "4. **–ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å**:\n",
    "   - DistilGPT-2 –æ–±—É—á–∞–ª–∞—Å—å –Ω–∞ –æ–≥—Ä–æ–º–Ω–æ–º –∫–æ—Ä–ø—É—Å–µ, —á—Ç–æ –¥–∞—ë—Ç –µ–π –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ –≤ –ø–æ–Ω–∏–º–∞–Ω–∏–∏ —è–∑—ã–∫–∞.\n",
    "   - LSTM —Ç—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b1ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "import os\n",
    "\n",
    "print(\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Ç–æ–≥–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
    "if 'results_df' not in globals():\n",
    "    raise NameError(\"–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è results_df –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –í—ã–ø–æ–ª–Ω–∏—Ç–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π.\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ\n",
    "try:\n",
    "    results_df.to_csv(\"results/comparison_results.csv\", index=False)\n",
    "    print(\"‚úÖ –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ results/comparison_results.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: {e}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
