{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac6d7103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫\n",
    "!pip install torch --quiet\n",
    "!pip install transformers --quiet\n",
    "!pip install rouge-score --quiet\n",
    "!pip install pandas numpy scikit-learn tqdm --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf1e1bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cpu\n"
     ]
    }
   ],
   "source": [
    "# –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd93fde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—É—Ç—å: /Users/adam/projects/auto_complete_model/src\n",
      "‚úÖ –§–∞–π–ª –Ω–∞–π–¥–µ–Ω: /Users/adam/projects/auto_complete_model/src/data_utils.py\n",
      "üöÄ –ó–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/projects/auto_complete_model/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞: data/raw_dataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/projects/auto_complete_model/src/data_utils.py:49: DtypeWarning: Columns (5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,24,29,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(RAW_DATA_PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤: 1048498\n",
      "–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤ –æ—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏–π, —Ö–µ—à—Ç–µ–≥–æ–≤ –∏ —Å—Å—ã–ª–æ–∫...\n",
      "–¢–µ–∫—Å—Ç–æ–≤ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: 800654\n",
      "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–µ—Ä–≤—ã—Ö 7000 —Ç–µ–∫—Å—Ç–æ–≤.\n",
      "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...\n",
      "–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: data/dataset_processed.csv\n",
      "–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val/test (80%/10%/10%)...\n",
      "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ 5600 —Ç–µ–∫—Å—Ç–æ–≤ –≤ data/train.csv\n",
      "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ 700 —Ç–µ–∫—Å—Ç–æ–≤ –≤ data/val.csv\n",
      "–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ 700 —Ç–µ–∫—Å—Ç–æ–≤ –≤ data/test.csv\n",
      "–†–∞–∑–º–µ—Ä—ã –≤—ã–±–æ—Ä–æ–∫: train=5600, val=700, test=700\n",
      "–ó–∞–≥—Ä—É–∑–∫–∞ BERT-—Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞...\n",
      "–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—É—á–∞—é—â–µ–≥–æ, –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –∏ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤...\n",
      "–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: 62648\n",
      "–†–∞–∑–º–µ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: 7800\n",
      "–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: 7969\n",
      "–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ `data_utils.py`\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# –£–∫–∞–∑—ã–≤–∞–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—é\n",
    "src_dir = Path(\"src\").resolve()\n",
    "\n",
    "# –î–æ–±–∞–≤–ª—è–µ–º –≤ sys.path, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ (–¥–ª—è –∏–º–ø–æ—Ä—Ç–∞)\n",
    "if str(src_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(src_dir))\n",
    "\n",
    "print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—É—Ç—å: {src_dir}\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞\n",
    "data_utils_path = src_dir / \"data_utils.py\"\n",
    "if not data_utils_path.exists():\n",
    "    raise FileNotFoundError(f\"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {data_utils_path}\")\n",
    "\n",
    "print(f\"‚úÖ –§–∞–π–ª –Ω–∞–π–¥–µ–Ω: {data_utils_path}\")\n",
    "\n",
    "print(\"üöÄ –ó–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏...\")\n",
    "%run -i \"src/data_utils.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c7857cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞ (train)\n",
      "   ‚Üí –†–∞–∑–º–µ—Ä: 5600 –∑–∞–ø–∏—Å–µ–π\n",
      "   ‚Üí –ü—Ä–∏–º–µ—Ä—ã —Ç–µ–∫—Å—Ç–æ–≤:\n",
      "     1. aww i want one too baka next week hahaha\n",
      "     2. nah im going 2 use my work resources next week 4 all of us amp if that fails then it will be payola\n",
      "     3. i am not digging the taste of water right now at all\n",
      "--------------------------------------------------\n",
      "‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ (val)\n",
      "   ‚Üí –†–∞–∑–º–µ—Ä: 700 –∑–∞–ø–∏—Å–µ–π\n",
      "   ‚Üí –ü—Ä–∏–º–µ—Ä—ã —Ç–µ–∫—Å—Ç–æ–≤:\n",
      "     1. ber sick trying to muster up the strength to head into work\n",
      "     2. argh there goes my plans for friday\n",
      "     3. why did i go to bed so late last night uuughhhh f my life im off to work\n",
      "--------------------------------------------------\n",
      "‚úÖ –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞ (test)\n",
      "   ‚Üí –†–∞–∑–º–µ—Ä: 700 –∑–∞–ø–∏—Å–µ–π\n",
      "   ‚Üí –ü—Ä–∏–º–µ—Ä—ã —Ç–µ–∫—Å—Ç–æ–≤:\n",
      "     1. hopes pappaw franks heart surgery helps him today keep thinking good thoughts\n",
      "     2. why cant i breathe yes an overexaggeration in terms but still i hate being ill\n",
      "     3. zen sushi for lunch todaylooks like its raining outside\n",
      "--------------------------------------------------\n",
      "üìä –°–≤–æ–¥–∫–∞ –ø–æ –≤—ã–±–æ—Ä–∫–∞–º\n",
      "\n",
      "                    –í—ã–±–æ—Ä–∫–∞  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–∫—Å—Ç–æ–≤  –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ (—Å–ª–æ–≤)  –ú–∏–Ω. –¥–ª–∏–Ω–∞ (—Å–ª–æ–≤)  –ú–∞–∫—Å. –¥–ª–∏–Ω–∞ (—Å–ª–æ–≤)\n",
      "  –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞ (train)                5600                  15.1                  7                  32\n",
      "–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ (val)                 700                  15.1                  7                  34\n",
      "    –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞ (test)                 700                  15.4                  7                  31\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–æ—Å–º–æ—Ç—Ä –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "# \n",
    "# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ:\n",
    "# - `train.csv`\n",
    "# - `val.csv`\n",
    "# - `test.csv`\n",
    "# \n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤.\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º\n",
    "TRAIN_DATA_PATH = \"data/train.csv\"\n",
    "VAL_DATA_PATH = \"data/val.csv\"\n",
    "TEST_DATA_PATH = \"data/test.csv\"\n",
    "\n",
    "# –°–ø–∏—Å–æ–∫ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "files = {\n",
    "    \"–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞ (train)\": TRAIN_DATA_PATH,\n",
    "    \"–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ (val)\": VAL_DATA_PATH,\n",
    "    \"–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞ (test)\": TEST_DATA_PATH\n",
    "}\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–æ–≤ –∏ –∑–∞–≥—Ä—É–∑–∫–∞\n",
    "datasets = {}\n",
    "\n",
    "for name, path in files.items():\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}\")\n",
    "        datasets[name] = None\n",
    "        continue\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    datasets[name] = df\n",
    "    \n",
    "    print(f\"‚úÖ {name}\")\n",
    "    print(f\"   ‚Üí –†–∞–∑–º–µ—Ä: {len(df)} –∑–∞–ø–∏—Å–µ–π\")\n",
    "    print(f\"   ‚Üí –ü—Ä–∏–º–µ—Ä—ã —Ç–µ–∫—Å—Ç–æ–≤:\")\n",
    "    for i, text in enumerate(df[\"text\"].head(3)):\n",
    "        print(f\"     {i+1}. {text}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞\n",
    "print(\"üìä –°–≤–æ–¥–∫–∞ –ø–æ –≤—ã–±–æ—Ä–∫–∞–º\")\n",
    "summary = []\n",
    "for name, df in datasets.items():\n",
    "    if df is not None:\n",
    "        summary.append({\n",
    "            \"–í—ã–±–æ—Ä–∫–∞\": name,\n",
    "            \"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–∫—Å—Ç–æ–≤\": len(df),\n",
    "            \"–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ (—Å–ª–æ–≤)\": round(df[\"text\"].str.split().str.len().mean(), 1),\n",
    "            \"–ú–∏–Ω. –¥–ª–∏–Ω–∞ (—Å–ª–æ–≤)\": df[\"text\"].str.split().str.len().min(),\n",
    "            \"–ú–∞–∫—Å. –¥–ª–∏–Ω–∞ (—Å–ª–æ–≤)\": df[\"text\"].str.split().str.len().max(),\n",
    "        })\n",
    "\n",
    "if summary:\n",
    "    summary_df = pd.DataFrame(summary)\n",
    "    print(\"\")\n",
    "    print(summary_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eb4eb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è LSTM...\n",
      "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cpu\n",
      "–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è...\n",
      "–†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è: 3958\n",
      "–°–ª–æ–≤–∞—Ä—å —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ models/vocab.pkl\n",
      "–î–∞—Ç–∞–ª–æ–∞–¥–µ—Ä –¥–ª—è train —Å–æ–∑–¥–∞–Ω: 5600 –ø—Ä–∏–º–µ—Ä–æ–≤, –±–∞—Ç—á=64\n",
      "–î–∞—Ç–∞–ª–æ–∞–¥–µ—Ä –¥–ª—è val —Å–æ–∑–¥–∞–Ω: 700 –ø—Ä–∏–º–µ—Ä–æ–≤, –±–∞—Ç—á=64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–≠–ø–æ—Ö–∞ 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6.7690, Train Acc: 0.0577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5.9833, Val Acc: 0.1120\n",
      "–ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è:\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'hello how are'\n",
      "  'hello how are' ‚Üí 'for station cant him 2 one always will a my'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'the weather today'\n",
      "  'the weather today' ‚Üí 'having its i bad to im today in with your'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'i want to tell'\n",
      "  'i want to tell' ‚Üí 'one cant cake on im them in and lack in'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'in the bank there was'\n",
      "  'in the bank there was' ‚Üí 'no only back just my me a is to work'\n",
      "\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/lstm_model.pth\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/lstm_model.pth\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6.2335, Train Acc: 0.0782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5.9330, Val Acc: 0.1120\n",
      "–ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è:\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'hello how are'\n",
      "  'hello how are' ‚Üí 'see but do so the the now time at in'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'the weather today'\n",
      "  'the weather today' ‚Üí 'for for see just fault be when at all funny'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'i want to tell'\n",
      "  'i want to tell' ‚Üí 'not the work now a it to can to and'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'in the bank there was'\n",
      "  'in the bank there was' ‚Üí 'teeth not back to my and meds at the crap'\n",
      "\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/lstm_model.pth\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/lstm_model.pth\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6.2013, Train Acc: 0.0783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5.9184, Val Acc: 0.1120\n",
      "–ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è:\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'hello how are'\n",
      "  'hello how are' ‚Üí 'the on hard i whole or quiet its it this'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'the weather today'\n",
      "  'the weather today' ‚Üí 'i stopped close can you woke soon not to but'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'i want to tell'\n",
      "  'i want to tell' ‚Üí 'being to the able really you down about to is'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'in the bank there was'\n",
      "  'in the bank there was' ‚Üí 'this to lovely have late though is and up of'\n",
      "\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/lstm_model.pth\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/lstm_model.pth\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6.1858, Train Acc: 0.0783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5.9189, Val Acc: 0.1120\n",
      "–ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è:\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'hello how are'\n",
      "  'hello how are' ‚Üí 'my even the we to work lol in so had'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'the weather today'\n",
      "  'the weather today' ‚Üí 'seem going been be happy your the we long sleep'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'i want to tell'\n",
      "  'i want to tell' ‚Üí 'with two night was can the over capacity morning just'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'in the bank there was'\n",
      "  'in the bank there was' ‚Üí 'about of fun of lol me cool be feel from'\n",
      "\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6.1672, Train Acc: 0.0782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5.8853, Val Acc: 0.1118\n",
      "–ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è:\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'hello how are'\n",
      "  'hello how are' ‚Üí 'but is having for and of my hurts in the'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'the weather today'\n",
      "  'the weather today' ‚Üí 'for out been hours i i my the to want'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'i want to tell'\n",
      "  'i want to tell' ‚Üí 'is my think italy cold too to night pictures this'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'in the bank there was'\n",
      "  'in the bank there was' ‚Üí 'go confused wet dont and now i damn a then'\n",
      "\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/lstm_model.pth\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/lstm_model.pth\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6.1227, Train Acc: 0.0799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5.8549, Val Acc: 0.1111\n",
      "–ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è:\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'hello how are'\n",
      "  'hello how are' ‚Üí 'late to and about time to my its is you'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'the weather today'\n",
      "  'the weather today' ‚Üí 'a killing im in and couple on night loads cant'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'i want to tell'\n",
      "  'i want to tell' ‚Üí 'out too in the of the and a and to'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'in the bank there was'\n",
      "  'in the bank there was' ‚Üí 'its my looked my my it to things my in'\n",
      "\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/lstm_model.pth\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/lstm_model.pth\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6.0890, Train Acc: 0.0834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5.8275, Val Acc: 0.1089\n",
      "–ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è:\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'hello how are'\n",
      "  'hello how are' ‚Üí 'at say way stop right this city on lines be'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'the weather today'\n",
      "  'the weather today' ‚Üí 'you and think i a and in speak to go'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'i want to tell'\n",
      "  'i want to tell' ‚Üí 'love sleep work i to that is your my option'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'in the bank there was'\n",
      "  'in the bank there was' ‚Üí 'left families now to but what was out play my'\n",
      "\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/lstm_model.pth\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/lstm_model.pth\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6.0618, Train Acc: 0.0859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5.8082, Val Acc: 0.1166\n",
      "–ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è:\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'hello how are'\n",
      "  'hello how are' ‚Üí 'i ill be in bullshit is a something the keep'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'the weather today'\n",
      "  'the weather today' ‚Üí 'a crash i to sims me i think to yet'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'i want to tell'\n",
      "  'i want to tell' ‚Üí 'find or out of essay for with the about kinda'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'in the bank there was'\n",
      "  'in the bank there was' ‚Üí 'amp time theyre of work fish dont life girl only'\n",
      "\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/lstm_model.pth\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/lstm_model.pth\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6.0398, Train Acc: 0.0875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5.7934, Val Acc: 0.1173\n",
      "–ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è:\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'hello how are'\n",
      "  'hello how are' ‚Üí 'it i could killing my getting to me any let'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'the weather today'\n",
      "  'the weather today' ‚Üí 'i to car i sorry want im late i i'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'i want to tell'\n",
      "  'i want to tell' ‚Üí 'be on long windows up on up when that at'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'in the bank there was'\n",
      "  'in the bank there was' ‚Üí 'go now was i away two today didnt its for'\n",
      "\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/lstm_model.pth\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/lstm_model.pth\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6.0116, Train Acc: 0.0891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 5.7712, Val Acc: 0.1188\n",
      "–ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è:\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'hello how are'\n",
      "  'hello how are' ‚Üí 'going a seeing shame get home and and to the'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'the weather today'\n",
      "  'the weather today' ‚Üí 'but i been friends i to completed be the time'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'i want to tell'\n",
      "  'i want to tell' ‚Üí 'phone did laughing to boy at weather at which want'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'in the bank there was'\n",
      "  'in the bank there was' ‚Üí 'to up boo i to her a door never i'\n",
      "\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ models/lstm_model.pth\n",
      "–ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/lstm_model.pth\n",
      "–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.\n",
      "\n",
      "–ó–∞–ø—É—Å–∫ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –ø–æ ROUGE –Ω–∞ val-–≤—ã–±–æ—Ä–∫–µ...\n",
      "–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ val –≤—ã–±–æ—Ä–∫–µ...\n",
      "[VOCAB] –ó–∞–≥—Ä—É–∂–µ–Ω —Å–ª–æ–≤–∞—Ä—å –∏–∑ models/vocab.pkl, —Ä–∞–∑–º–µ—Ä: 3958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:01<00:00, 457.35—Ç–µ–∫—Å—Ç/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: 0.0451\n",
      "ROUGE-2: 0.0016\n",
      "ROUGE-L: 0.0434\n",
      "–§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ ROUGE:\n",
      "  ROUGE1: 0.0451\n",
      "  ROUGE2: 0.0016\n",
      "  ROUGEL: 0.0434\n",
      "‚úÖ –û–±—É—á–µ–Ω–∏–µ LSTM –∑–∞–≤–µ—Ä—à–µ–Ω–æ.\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è LSTM\n",
    "import os\n",
    "\n",
    "print(\"–ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è LSTM...\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "required_files = [\"data/train.csv\", \"data/val.csv\"]\n",
    "for f in required_files:\n",
    "    if not os.path.exists(f):\n",
    "        raise FileNotFoundError(f\"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {f}. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É.\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏ –¥–ª—è –º–æ–¥–µ–ª–µ–π\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# –ò–º–ø–æ—Ä—Ç\n",
    "try:\n",
    "    from src.lstm_train import train_model\n",
    "except ImportError as e:\n",
    "    raise ImportError(f\"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å train_model: {e}. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∏ —Ñ–∞–π–ª src/lstm_train.py.\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è DEVICE\n",
    "if 'DEVICE' not in globals():\n",
    "    raise NameError(\"–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è DEVICE –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ DEVICE = 'cuda' –∏–ª–∏ 'cpu'.\")\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è\n",
    "try:\n",
    "    train_model(\n",
    "        num_epochs=10,\n",
    "        batch_size=64,\n",
    "        lr=1e-3,\n",
    "        hidden_size=128,\n",
    "        embedding_dim=128,\n",
    "        context_length=50,\n",
    "        device=DEVICE\n",
    "    )\n",
    "    print(\"‚úÖ –û–±—É—á–µ–Ω–∏–µ LSTM –∑–∞–≤–µ—Ä—à–µ–Ω–æ.\")\n",
    "except TypeError as e:\n",
    "    if \"unexpected keyword argument\" in str(e):\n",
    "        print(\"‚ùå –û—à–∏–±–∫–∞: train_model() –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–¥–∏–Ω –∏–∑ –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\")\n",
    "        print(\"üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—ã –æ–±–Ω–æ–≤–∏–ª–∏ —Ñ–∞–π–ª src/lstm_train.py —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\")\n",
    "    raise e\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ LSTM: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "520a030c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ LSTM –¥–ª—è –æ—Ü–µ–Ω–∫–∏...\n",
      "–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ models/lstm_model.pth\n",
      "‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ –≤ —Ä–µ–∂–∏–º eval. –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cpu\n",
      "–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ val –≤—ã–±–æ—Ä–∫–µ...\n",
      "[VOCAB] –ó–∞–≥—Ä—É–∂–µ–Ω —Å–ª–æ–≤–∞—Ä—å –∏–∑ models/vocab.pkl, —Ä–∞–∑–º–µ—Ä: 3958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:01<00:00, 454.04—Ç–µ–∫—Å—Ç/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: 0.0466\n",
      "ROUGE-2: 0.0007\n",
      "ROUGE-L: 0.0438\n",
      "\n",
      "‚úÖ –û—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ.\n",
      "ROUGE-1: 0.0466\n",
      "ROUGE-2: 0.0007\n",
      "ROUGE-L: 0.0438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# –û—Ü–µ–Ω–∫–∞ LSTM —Å –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ–º ROUGE\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from src.eval_lstm import evaluate_on_dataset\n",
    "from src.lstm_model import LSTMModel\n",
    "\n",
    "print(\"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ LSTM –¥–ª—è –æ—Ü–µ–Ω–∫–∏...\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–æ–≤\n",
    "model_path = \"models/lstm_model.pth\"\n",
    "vocab_path = \"models/vocab.pkl\"\n",
    "\n",
    "for path, name in [(vocab_path, \"—Å–ª–æ–≤–∞—Ä—è\"), (model_path, \"–º–æ–¥–µ–ª–∏\")]:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"{name} –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}\")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤–∞—Ä—è\n",
    "with open(vocab_path, \"rb\") as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "pad_idx = vocab[\"<PAD>\"]\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "model = LSTMModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=128,\n",
    "    hidden_dim=128,\n",
    "    num_layers=2,\n",
    "    dropout=0.3,\n",
    "    pad_idx=pad_idx\n",
    ").to(DEVICE)\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤\n",
    "model.load(model_path, device=DEVICE)\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ –≤ —Ä–µ–∂–∏–º eval. –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {DEVICE}\")\n",
    "\n",
    "# –û—Ü–µ–Ω–∫–∞\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        lstm_rouge = evaluate_on_dataset(\n",
    "            model=model,\n",
    "            split=\"val\",\n",
    "            batch_size=64,\n",
    "            max_samples=500,\n",
    "            device=DEVICE,\n",
    "            max_gen_tokens=15\n",
    "        )\n",
    "\n",
    "    print(\"\\n‚úÖ –û—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ.\")\n",
    "    print(f\"ROUGE-1: {lstm_rouge.get('rouge1', 0):.4f}\")\n",
    "    print(f\"ROUGE-2: {lstm_rouge.get('rouge2', 0):.4f}\")\n",
    "    print(f\"ROUGE-L: {lstm_rouge.get('rougeL', 0):.4f}\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\n‚ùå –û—Ü–µ–Ω–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º (Ctrl+C).\")\n",
    "    print(\"–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–º–µ–Ω—å—à–∏—Ç—å max_samples –∏–ª–∏ max_gen_length.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43a71a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–ø—É—Å–∫ –æ—Ü–µ–Ω–∫–∏ DistilGPT-2...\n",
      "‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –æ—Ü–µ–Ω–∫–∞ DistilGPT-2 –Ω–∞ CPU –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 10+ –º–∏–Ω—É—Ç. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU.\n",
      "–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –∏ –º–æ–¥–µ–ª–∏: distilgpt2\n",
      "‚ö†Ô∏è pad_token –Ω–µ –∑–∞–¥–∞–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è eos_token –∫–∞–∫ pad_token.\n",
      "–û—Ü–µ–Ω–∫–∞ –Ω–∞ val (max_samples=500)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:22<00:00, 21.83—Ç–µ–∫—Å—Ç/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –¥–ª—è –æ—Ü–µ–Ω–∫–∏: 498 –ø—Ä–∏–º–µ—Ä–æ–≤\n",
      "‚úÖ –û—Ü–µ–Ω–∫–∞ DistilGPT-2 –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\n",
      "ROUGE-1: 0.0567\n",
      "ROUGE-2: 0.0098\n",
      "ROUGE-L: 0.0565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# –û—Ü–µ–Ω–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ DistilGPT-2\n",
    "import torch\n",
    "\n",
    "print(\"–ó–∞–ø—É—Å–∫ –æ—Ü–µ–Ω–∫–∏ DistilGPT-2...\")\n",
    "\n",
    "# –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "if DEVICE == \"cpu\":\n",
    "    print(\"‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –æ—Ü–µ–Ω–∫–∞ DistilGPT-2 –Ω–∞ CPU –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 10+ –º–∏–Ω—É—Ç. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU.\")\n",
    "\n",
    "# –ò–º–ø–æ—Ä—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "from src.eval_transformer_pipeline import evaluate_transformer\n",
    "\n",
    "try:\n",
    "    transformer_rouge = evaluate_transformer(\n",
    "        model_name=\"distilgpt2\",\n",
    "        split=\"val\",\n",
    "        max_samples=500,\n",
    "        max_length=30,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    print(\"‚úÖ –û—Ü–µ–Ω–∫–∞ DistilGPT-2 –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\")\n",
    "\n",
    "    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "    print(f\"ROUGE-1: {transformer_rouge['rouge1']:.4f}\")\n",
    "    print(f\"ROUGE-2: {transformer_rouge['rouge2']:.4f}\")\n",
    "    print(f\"ROUGE-L: {transformer_rouge['rougeL']:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ DistilGPT-2: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56f87546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ ROUGE-–º–µ—Ç—Ä–∏–∫–∞–º:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d2283_row0_col1, #T_d2283_row0_col2, #T_d2283_row0_col3 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d2283\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d2283_level0_col0\" class=\"col_heading level0 col0\" >–ú–æ–¥–µ–ª—å</th>\n",
       "      <th id=\"T_d2283_level0_col1\" class=\"col_heading level0 col1\" >ROUGE-1</th>\n",
       "      <th id=\"T_d2283_level0_col2\" class=\"col_heading level0 col2\" >ROUGE-2</th>\n",
       "      <th id=\"T_d2283_level0_col3\" class=\"col_heading level0 col3\" >ROUGE-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d2283_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d2283_row0_col0\" class=\"data row0 col0\" >DistilGPT-2</td>\n",
       "      <td id=\"T_d2283_row0_col1\" class=\"data row0 col1\" >0.056700</td>\n",
       "      <td id=\"T_d2283_row0_col2\" class=\"data row0 col2\" >0.009800</td>\n",
       "      <td id=\"T_d2283_row0_col3\" class=\"data row0 col3\" >0.056500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d2283_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d2283_row1_col0\" class=\"data row1 col0\" >LSTM</td>\n",
       "      <td id=\"T_d2283_row1_col1\" class=\"data row1 col1\" >0.046600</td>\n",
       "      <td id=\"T_d2283_row1_col2\" class=\"data row1 col2\" >0.000700</td>\n",
       "      <td id=\"T_d2283_row1_col3\" class=\"data row1 col3\" >0.043800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x142316180>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫\n",
    "print(\"–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ ROUGE-–º–µ—Ç—Ä–∏–∫–∞–º:\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
    "if 'lstm_rouge' not in globals():\n",
    "    raise NameError(\"–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è lstm_rouge –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –æ—Ü–µ–Ω–∫—É LSTM.\")\n",
    "if 'transformer_rouge' not in globals():\n",
    "    raise NameError(\"–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è transformer_rouge –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –í—ã–ø–æ–ª–Ω–∏—Ç–µ –æ—Ü–µ–Ω–∫—É DistilGPT-2.\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã\n",
    "results = {\n",
    "    \"–ú–æ–¥–µ–ª—å\": [\"LSTM\", \"DistilGPT-2\"],\n",
    "    \"ROUGE-1\": [lstm_rouge['rouge1'], transformer_rouge['rouge1']],\n",
    "    \"ROUGE-2\": [lstm_rouge['rouge2'], transformer_rouge['rouge2']],\n",
    "    \"ROUGE-L\": [lstm_rouge['rougeL'], transformer_rouge['rougeL']],\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ ROUGE-1\n",
    "results_df = results_df.sort_values(by=\"ROUGE-1\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# –í—ã–≤–æ–¥ —Å –ø–æ–¥—Å–≤–µ—Ç–∫–æ–π –º–∞–∫—Å–∏–º—É–º–æ–≤\n",
    "display(results_df.round(4).style.highlight_max(color='lightgreen', subset=[\"ROUGE-1\", \"ROUGE-2\", \"ROUGE-L\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4f7a947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== –ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è ===\n",
      "\n",
      "–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cpu\n",
      "\n",
      "=== LSTM: –ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è ===\n",
      "‚úÖ –°–ª–æ–≤–∞—Ä—å reverse_vocab –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ models/reverse_vocab.pkl\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'hello how are'\n",
      "  'hello how are' ‚Üí 'going no and that much where sorry but to last that dont i to sunshine'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'the weather today'\n",
      "  'the weather today' ‚Üí 'that need i im is check a the find snowing me is and moving least'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'i want to tell'\n",
      "  'i want to tell' ‚Üí 'me per painful as sorry have have to morning today just you had theyre ok'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'in the park there was'\n",
      "  'in the park there was' ‚Üí 'and to weather writing i wait to come and you to love that all parcel'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'good morning and thank you'\n",
      "  'good morning and thank you' ‚Üí 'to the life the a one and i to now up to but like to'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'this story begins with'\n",
      "  'this story begins with' ‚Üí 'on the my are they works bad so the and the gone he could it'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'if you ever feel'\n",
      "  'if you ever feel' ‚Üí 'might while really up never is a the last sure a of break at of'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'my favorite book is'\n",
      "  'my favorite book is' ‚Üí '13 to check of of school im all of hair bad in of get of'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'we decided to go'\n",
      "  'we decided to go' ‚Üí 'did and to that got forward with on better message see my good but even'\n",
      "[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'it started to rain'\n",
      "  'it started to rain' ‚Üí 'in hold i i does at one have to put im a for turn to'\n",
      "\n",
      "\n",
      "=== DistilGPT-2: –ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è ===\n",
      "–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ DistilGPT-2...\n",
      "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å max_new_tokens=15...\n",
      "\n",
      "[GPT-2] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'hello how are'\n",
      "  'hello how are' ‚Üí ' we going to do that?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The reason is that'\n",
      "[GPT-2] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'the weather today'\n",
      "  'the weather today' ‚Üí ' was a bit of a surprise as I was going to try and get the'\n",
      "[GPT-2] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'i want to tell'\n",
      "  'i want to tell' ‚Üí ' us about the past and the future.‚Äù\n",
      "\n",
      "\n",
      "\n",
      "If'\n",
      "[GPT-2] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'in the park there was'\n",
      "  'in the park there was' ‚Üí ' a car park. It was a nice place to hang out with kids.'\n",
      "[GPT-2] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'good morning and thank you'\n",
      "  'good morning and thank you' ‚Üí ' for all the support you've received in the last few days.\n",
      "\n",
      "'\n",
      "[GPT-2] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'this story begins with'\n",
      "  'this story begins with' ‚Üí ' the death of the mother, the death of a man with a heart that'\n",
      "[GPT-2] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'if you ever feel'\n",
      "  'if you ever feel' ‚Üí ' like you're going to have to deal with the problems for them, but'\n",
      "[GPT-2] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'my favorite book is'\n",
      "  'my favorite book is' ‚Üí ' the book of the year by the famous British novelist, Jules Verne'\n",
      "[GPT-2] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'we decided to go'\n",
      "  'we decided to go' ‚Üí ' back to work when I felt like I was getting a little too frustrated.'\n",
      "[GPT-2] –û–±—Ä–∞–±–æ—Ç–∫–∞: 'it started to rain'\n",
      "  'it started to rain' ‚Üí ' in the afternoon as the sun set in on the evening.\n",
      "\n",
      "\n",
      "'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === –ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è ‚Äî LSTM –∏ DistilGPT-2 ===\n",
    "print(\"=== –ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è ===\\n\")\n",
    "\n",
    "# –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {DEVICE}\\n\")\n",
    "\n",
    "# –¢–µ–∫—Å—Ç—ã –¥–ª—è –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è\n",
    "sample_texts = [\n",
    "    \"hello how are\",\n",
    "    \"the weather today\",\n",
    "    \"i want to tell\",\n",
    "    \"in the park there was\",\n",
    "    \"good morning and thank you\",\n",
    "    \"this story begins with\",\n",
    "    \"if you ever feel\",\n",
    "    \"my favorite book is\",\n",
    "    \"we decided to go\",\n",
    "    \"it started to rain\"\n",
    "]\n",
    "\n",
    "# üîΩ –Ø–í–ù–´–ô –ò–ú–ü–û–†–¢ –§–£–ù–ö–¶–ò–ô\n",
    "from src.eval_lstm import generate_examples\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "# === LSTM: –ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è ===\n",
    "print(\"=== LSTM: –ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è ===\")\n",
    "\n",
    "# –ü—É—Ç–∏ –∫ —Å–ª–æ–≤–∞—Ä—è–º\n",
    "vocab_path = \"models/vocab.pkl\"\n",
    "reverse_vocab_path = \"models/reverse_vocab.pkl\"  # –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ‚Äî —Å–æ–∑–¥–∞–¥–∏–º\n",
    "\n",
    "try:\n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º vocab, –µ—Å–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω\n",
    "    if 'vocab' not in globals():\n",
    "        if not os.path.exists(vocab_path):\n",
    "            raise FileNotFoundError(f\"–§–∞–π–ª —Å–ª–æ–≤–∞—Ä—è –Ω–µ –Ω–∞–π–¥–µ–Ω: {vocab_path}\")\n",
    "        with open(vocab_path, \"rb\") as f:\n",
    "            vocab = pickle.load(f)\n",
    "        print(f\"‚úÖ –°–ª–æ–≤–∞—Ä—å vocab –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ {vocab_path}\")\n",
    "\n",
    "    # –°–æ–∑–¥–∞—ë–º reverse_vocab, –µ—Å–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω\n",
    "    if 'reverse_vocab' not in globals():\n",
    "        if os.path.exists(reverse_vocab_path):\n",
    "            with open(reverse_vocab_path, \"rb\") as f:\n",
    "                reverse_vocab = pickle.load(f)\n",
    "            print(f\"‚úÖ –°–ª–æ–≤–∞—Ä—å reverse_vocab –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ {reverse_vocab_path}\")\n",
    "        else:\n",
    "            # –°–æ–∑–¥–∞—ë–º –∏–∑ vocab\n",
    "            reverse_vocab = {idx: token for token, idx in vocab.items()}\n",
    "            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n",
    "            os.makedirs(\"models\", exist_ok=True)\n",
    "            with open(reverse_vocab_path, \"wb\") as f:\n",
    "                pickle.dump(reverse_vocab, f)\n",
    "            print(\"‚úÖ –°–ª–æ–≤–∞—Ä—å reverse_vocab —Å–æ–∑–¥–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ models/reverse_vocab.pkl\")\n",
    "\n",
    "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ LSTM\n",
    "    if 'model' not in globals():\n",
    "        raise NameError(\"–ú–æ–¥–µ–ª—å LSTM (model) –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –í—ã–ø–æ–ª–Ω–∏—Ç–µ —è—á–µ–π–∫—É –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏.\")\n",
    "\n",
    "    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–º–µ—Ä–æ–≤\n",
    "    generate_examples(\n",
    "        model=model,\n",
    "        sample_texts=sample_texts,\n",
    "        vocab=vocab,\n",
    "        reverse_vocab=reverse_vocab,\n",
    "        device=DEVICE,\n",
    "        max_gen_tokens=15,\n",
    "        context_length=50,\n",
    "        temperature=0.8\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ LSTM: {type(e).__name__}: {e}\\n\")\n",
    "\n",
    "\n",
    "# === DistilGPT-2: –ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è ===\n",
    "print(\"\\n=== DistilGPT-2: –ü—Ä–∏–º–µ—Ä—ã –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è ===\")\n",
    "\n",
    "try:\n",
    "    print(\"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ DistilGPT-2...\")\n",
    "    gpt2_tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "    gpt2_model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
    "\n",
    "    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞\n",
    "    gpt2_tokenizer.padding_side = \"right\"\n",
    "    if gpt2_tokenizer.pad_token is None:\n",
    "        gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\n",
    "        gpt2_model.config.pad_token_id = gpt2_tokenizer.eos_token_id\n",
    "\n",
    "    # –ü–µ—Ä–µ–Ω–æ—Å –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\n",
    "    gpt2_model = gpt2_model.to(DEVICE)\n",
    "    gpt2_model.eval()\n",
    "\n",
    "    print(\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å max_new_tokens=15...\\n\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for text in sample_texts:\n",
    "            print(f\"[GPT-2] –û–±—Ä–∞–±–æ—Ç–∫–∞: '{text}'\")\n",
    "            try:\n",
    "                # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è\n",
    "                inputs = gpt2_tokenizer(\n",
    "                    text.strip(),\n",
    "                    return_tensors=\"pt\",\n",
    "                    padding=True,\n",
    "                    truncation=True,\n",
    "                    max_length=512\n",
    "                ).to(DEVICE)\n",
    "\n",
    "                input_ids = inputs[\"input_ids\"]\n",
    "                attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è\n",
    "                outputs = gpt2_model.generate(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    max_new_tokens=15,\n",
    "                    temperature=0.7,\n",
    "                    do_sample=True,\n",
    "                    pad_token_id=gpt2_tokenizer.eos_token_id,\n",
    "                    eos_token_id=gpt2_tokenizer.eos_token_id\n",
    "                )\n",
    "\n",
    "                # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã\n",
    "                generated_tokens = outputs[0][input_ids.shape[-1]:]\n",
    "                generated_text = gpt2_tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "                print(f\"  '{text}' ‚Üí '{generated_text}'\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ùå –û—à–∏–±–∫–∞: {type(e).__name__}: {e}\")\n",
    "    print()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ DistilGPT-2: {type(e).__name__}: {e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61b1ec90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Ç–æ–≥–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...\n",
      "‚úÖ –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ results/comparison_results.csv\n"
     ]
    }
   ],
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "import os\n",
    "\n",
    "print(\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Ç–æ–≥–æ–≤—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
    "if 'results_df' not in globals():\n",
    "    raise NameError(\"–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è results_df –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –í—ã–ø–æ–ª–Ω–∏—Ç–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π.\")\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ\n",
    "try:\n",
    "    results_df.to_csv(\"results/comparison_results.csv\", index=False)\n",
    "    print(\"‚úÖ –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ results/comparison_results.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50309d22",
   "metadata": {},
   "source": [
    "## –í—ã–≤–æ–¥—ã:\n",
    "\n",
    "–ü—Ä–æ–≤–µ–¥–µ–Ω–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö –º–æ–¥–µ–ª–µ–π: LSTM –∏ DistilGPT-2.\n",
    "\n",
    "–ü–æ –º–µ—Ç—Ä–∏–∫–∞–º ROUGE:\n",
    "- DistilGPT-2 –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç LSTM –ø–æ –≤—Å–µ–º –º–µ—Ç—Ä–∏–∫–∞–º.\n",
    "- ROUGE-1: 0.0567 –ø—Ä–æ—Ç–∏–≤ 0.0466.\n",
    "- ROUGE-2: 0.0098 –ø—Ä–æ—Ç–∏–≤ 0.0007 ‚Äî –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ.\n",
    "- ROUGE-L: 0.0565 –ø—Ä–æ—Ç–∏–≤ 0.0438.\n",
    "\n",
    "–ü–æ –∫–∞—á–µ—Å—Ç–≤—É –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:\n",
    "- LSTM –≤—ã–¥–∞—ë—Ç –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ –∏ –Ω–µ—Å–≤—è–∑–Ω—ã–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è.\n",
    "- DistilGPT-2 –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ª–æ–≥–∏—á–Ω—ã–µ, –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∏ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã.\n",
    "- –ü—Ä–∏–º–µ—Ä—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ DistilGPT-2 –ø–æ–Ω–∏–º–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ —Å—Ç—Ä–æ–∏—Ç –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è.\n",
    "\n",
    "–í—ã–≤–æ–¥:\n",
    "- DistilGPT-2 –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç LSTM –∫–∞–∫ –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º, —Ç–∞–∫ –∏ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É —Ç–µ–∫—Å—Ç–∞.\n",
    "- LSTM –Ω–µ —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å –∑–∞–¥–∞—á–µ–π –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è.\n",
    "\n",
    "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:\n",
    "- –î–ª—è –∑–∞–¥–∞—á–∏ –∞–≤—Ç–æ–¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è —Å–ª–µ–¥—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å DistilGPT-2.\n",
    "- LSTM —Ç—Ä–µ–±—É–µ—Ç –¥–æ–æ–±—É—á–µ–Ω–∏—è –∏–ª–∏ –∑–∞–º–µ–Ω—ã –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã.\n",
    "\n",
    "–§–∏–Ω–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ DistilGPT-2 –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç –µ–≥–æ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
