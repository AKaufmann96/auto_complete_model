import torch
from torch.utils.data import DataLoader
from tqdm import tqdm
import numpy as np
from rouge_score import rouge_scorer
from typing import Dict, List, Tuple
import pandas as pd
import os
import pickle

from src.lstm_model import LSTMModel


def evaluate_model(
    model: LSTMModel,
    dataloader: DataLoader,
    criterion: torch.nn.Module,
    device: str = "cpu",
    pad_idx: int = 0
) -> Tuple[float, float]:
    """
    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –º–æ–¥–µ–ª—å –ø–æ loss –∏ accuracy —Å –º–∞—Å–∫–æ–π –Ω–∞ <PAD>.
    """
    model.eval()
    total_loss = 0.0
    correct = 0
    total = 0

    with torch.no_grad():
        for input_ids, target_ids in tqdm(dataloader, desc="Evaluating", leave=False):
            input_ids = input_ids.to(device)
            target_ids = target_ids.to(device)

            logits = model(input_ids)  # (B, T, V)

            # Reshape –¥–ª—è loss
            loss = criterion(
                logits.view(-1, logits.size(-1)),
                target_ids.view(-1)
            )
            total_loss += loss.item()

            # Accuracy —Å –º–∞—Å–∫–æ–π
            preds = torch.argmax(logits, dim=-1)  # (B, T)
            mask = target_ids != pad_idx
            n_correct = ((preds == target_ids) & mask).sum().item()
            n_total = mask.sum().item()

            correct += n_correct
            total += n_total

    avg_loss = total_loss / len(dataloader)
    accuracy = correct / total if total > 0 else 0.0
    return avg_loss, accuracy


def generate_completion(
    model: LSTMModel,
    input_text: str,
    vocab: dict,
    reverse_vocab: dict,
    device: str = "cpu",
    max_gen_length: int = 15,
    temperature: float = 0.7
) -> Tuple[str, str, str]:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–µ—Ä–≤—ã—Ö 3/4 —Ç–µ–∫—Å—Ç–∞.
    :return: (context, target, generated)
    """
    model.eval()
    with torch.no_grad():
        tokens = input_text.strip().lower().split()
        if len(tokens) < 2:
            return "", "", ""

        # –ë–µ—Ä—ë–º 3/4 –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç
        input_length = max(1, min(len(tokens) - 1, 3 * len(tokens) // 4))
        context = " ".join(tokens[:input_length])
        target = " ".join(tokens[input_length:])

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
        try:
            generated = model.generate(
                start_text=context,
                vocab=vocab,
                reverse_vocab=reverse_vocab,
                max_length=max_gen_length,
                temperature=temperature,
                device=device
            )
            # –ï—Å–ª–∏ model.generate –≤–µ—Ä–Ω—É–ª None –∏–ª–∏ –Ω–µ —Å—Ç—Ä–æ–∫—É
            if not isinstance(generated, str):
                generated = ""
        except Exception as e:
            print(f"[ERROR] –û—à–∏–±–∫–∞ –≤ model.generate –¥–ª—è '{context}': {e}")
            generated = ""

        return context, target, generated


def compute_rouge_scores(
    references: List[str],
    candidates: List[str],
    use_stemmer: bool = True
) -> Dict[str, float]:
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç —É—Å—Ä–µ–¥–Ω—ë–Ω–Ω—ã–µ ROUGE-–º–µ—Ç—Ä–∏–∫–∏.
    """
    scorer = rouge_scorer.RougeScorer(
        ['rouge1', 'rouge2', 'rougeL'],
        use_stemmer=use_stemmer
    )

    scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}

    for ref, cand in zip(references, candidates):
        if not ref.strip() or not cand.strip():
            continue
        score = scorer.score(ref, cand)
        scores['rouge1'].append(score['rouge1'].fmeasure)
        scores['rouge2'].append(score['rouge2'].fmeasure)
        scores['rougeL'].append(score['rougeL'].fmeasure)

    avg_scores = {k: np.mean(v) if v else 0.0 for k, v in scores.items()}
    return avg_scores


def generate_examples(
    model: LSTMModel,
    sample_texts: List[str],
    vocab: dict,
    reverse_vocab: dict,
    device: str,
    max_length: int = 10,
    temperature: float = 0.8
):
    """
    –í—ã–≤–æ–¥–∏—Ç –ø—Ä–∏–º–µ—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –æ—à–∏–±–æ–∫.
    """
    model.eval()
    with torch.no_grad():
        for text in sample_texts:
            print(f"[LSTM] –û–±—Ä–∞–±–æ—Ç–∫–∞: '{text}'")  # üîß –û—Ç–ª–∞–¥–∫–∞
            try:
                completion = model.generate(
                    start_text=text,
                    vocab=vocab,
                    reverse_vocab=reverse_vocab,
                    max_length=max_length,
                    temperature=temperature,
                    device=device
                )
                if not isinstance(completion, str):
                    completion = "<–Ω–µ —Å—Ç—Ä–æ–∫–∞>"
                print(f"  '{text}' ‚Üí '{completion}'")
            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è '{text}': {type(e).__name__}: {e}")
    print()


def evaluate_on_dataset(
    model: LSTMModel,
    split: str = "val",
    batch_size: int = 64,
    device: str = "cpu",
    max_samples: int = 500,
    max_gen_length: int = 15
) -> Dict[str, float]:
    """
    –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ LSTM –ø–æ ROUGE-–º–µ—Ç—Ä–∏–∫–∞–º –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
    """
    print(f"–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ {split} –≤—ã–±–æ—Ä–∫–µ...")

    path = {
        "train": "data/train.csv",
        "val": "data/val.csv",
        "test": "data/test.csv"
    }.get(split)

    if path is None:
        raise ValueError("split –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 'train', 'val' –∏–ª–∏ 'test'")

    if not os.path.exists(path):
        raise FileNotFoundError(f"–§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")

    df = pd.read_csv(path, dtype=str).fillna("")
    texts = df["text"].tolist()

    # üîß –ó–∞–≥—Ä—É–∑–∫–∞ vocab
    vocab = getattr(model, 'vocab', None)
    if vocab is None:
        vocab_path = "models/vocab.pkl"
        if not os.path.exists(vocab_path):
            raise FileNotFoundError(f"–§–∞–π–ª —Å–ª–æ–≤–∞—Ä—è –Ω–µ –Ω–∞–π–¥–µ–Ω: {vocab_path}")
        with open(vocab_path, "rb") as f:
            vocab = pickle.load(f)
        print(f"[VOCAB] –ó–∞–≥—Ä—É–∂–µ–Ω —Å–ª–æ–≤–∞—Ä—å –∏–∑ {vocab_path}, —Ä–∞–∑–º–µ—Ä: {len(vocab)}")
    else:
        print("[VOCAB] –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è vocab –∏–∑ –º–æ–¥–µ–ª–∏")

    reverse_vocab = {idx: token for token, idx in vocab.items()}
    references = []
    candidates = []
    processed = 0

    model.eval()
    torch.set_grad_enabled(False)

    pbar = tqdm(total=max_samples, desc="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è", unit="—Ç–µ–∫—Å—Ç")

    for text in texts:
        if processed >= max_samples:
            break
        text = text.strip()
        if not text:
            continue

        try:
            _, target, generated = generate_completion(
                model=model,
                input_text=text,
                vocab=vocab,
                reverse_vocab=reverse_vocab,
                device=device,
                max_gen_length=max_gen_length
            )

            # üîß –û—Ç–ª–∞–¥–∫–∞
            if not target.strip():
                print(f"[DEBUG] –ü—Ä–æ–ø—É—Å–∫: –ø—É—Å—Ç–æ–π target –¥–ª—è '{text}'")
            if not generated.strip():
                print(f"[DEBUG] –ü—Ä–æ–ø—É—Å–∫: –ø—É—Å—Ç–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è")

            if target.strip() and generated.strip():
                references.append(target)
                candidates.append(generated)
                processed += 1
                pbar.update(1)

        except Exception as e:
            print(f"[ERROR] –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è '{text}': {e}")
            continue

    pbar.close()

    if not references:
        print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞.")
        return {"rouge1": 0.0, "rouge2": 0.0, "rougeL": 0.0}

    rouge_scores = compute_rouge_scores(references, candidates, use_stemmer=True)

    print(f"ROUGE-1: {rouge_scores['rouge1']:.4f}")
    print(f"ROUGE-2: {rouge_scores['rouge2']:.4f}")
    print(f"ROUGE-L: {rouge_scores['rougeL']:.4f}")

    return {
        "rouge1": float(rouge_scores['rouge1']),
        "rouge2": float(rouge_scores['rouge2']),
        "rougeL": float(rouge_scores['rougeL'])
    }